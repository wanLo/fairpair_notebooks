{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Arena 55K Pairwise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_df = pd.read_csv(\"hf://datasets/lmsys/lmsys-arena-human-preference-55k/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_filtered = chatbot_df[chatbot_df.winner_tie == 0].drop(columns='winner_tie') # remove ties\n",
    "#chatbot_filtered = chatbot_filtered[~chatbot_filtered.prompt.str.startswith('[\"System')] # remove special tasks?\n",
    "chatbot_filtered['prompt'] = chatbot_filtered.prompt.str[2:-2] # cleanup prompt\n",
    "chatbot_filtered['response_a'] = chatbot_filtered.response_a.str[2:-2] # cleanup response A\n",
    "chatbot_filtered['response_b'] = chatbot_filtered.response_b.str[2:-2] # cleanup response A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>loser</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30192</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53567</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96401</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198779</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292873</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>Construct a rap battle, in the style of Epic R...</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "      <td>(Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>vicuna-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294656694</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>A simple mnemonic for \\u03c0:\\n\\\"How I wish I ...</td>\n",
       "      <td>Sure, let's break it down:\\n\\n1. \\\"How\\\" has 3...</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294692063</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure! Here's an implementation of a naive Baye...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294710549</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>is it unethical to work on building weapons?\",...</td>\n",
       "      <td>Working on weapons technology raises some ethi...</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294899228</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>If a bait contains 0,0025% bromadiolon then ho...</td>\n",
       "      <td>Bromadiolone is a rodenticide which is most of...</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>palm-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294947231</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>three kids eat three apples in three days, how...</td>\n",
       "      <td>27 apples</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39716 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_a              model_b  \\\n",
       "id                                                    \n",
       "30192       gpt-4-1106-preview           gpt-4-0613   \n",
       "53567                koala-13b           gpt-4-0613   \n",
       "96401         llama-2-13b-chat  mistral-7b-instruct   \n",
       "198779               koala-13b   gpt-3.5-turbo-0314   \n",
       "292873              vicuna-13b           gpt-4-0314   \n",
       "...                        ...                  ...   \n",
       "4294656694          gpt-4-0613             claude-1   \n",
       "4294692063          claude-2.0     llama-2-13b-chat   \n",
       "4294710549            claude-1           alpaca-13b   \n",
       "4294899228              palm-2       tulu-2-dpo-70b   \n",
       "4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                       prompt  \\\n",
       "id                                                              \n",
       "30192       Is it morally right to try to have a certain p...   \n",
       "53567       What is the difference between marriage licens...   \n",
       "96401       How can I create a test set for a very rare ca...   \n",
       "198779      What is the best way to travel from Tel-Aviv t...   \n",
       "292873      Construct a rap battle, in the style of Epic R...   \n",
       "...                                                       ...   \n",
       "4294656694  A simple mnemonic for \\u03c0:\\n\\\"How I wish I ...   \n",
       "4294692063  In python, implement a naive Bayes with gaussi...   \n",
       "4294710549  is it unethical to work on building weapons?\",...   \n",
       "4294899228  If a bait contains 0,0025% bromadiolon then ho...   \n",
       "4294947231  three kids eat three apples in three days, how...   \n",
       "\n",
       "                                                   response_a  \\\n",
       "id                                                              \n",
       "30192       The question of whether it is morally right to...   \n",
       "53567       A marriage license is a legal document that al...   \n",
       "96401       Creating a test set for a very rare category c...   \n",
       "198779      The best way to travel from Tel Aviv to Jerusa...   \n",
       "292873      [Zeus]\\nYo, it's the king of the gods on the m...   \n",
       "...                                                       ...   \n",
       "4294656694  Sure, let's break it down:\\n\\n1. \\\"How\\\" has 3...   \n",
       "4294692063  Here is an implementation of a naive Bayes cla...   \n",
       "4294710549  Working on weapons technology raises some ethi...   \n",
       "4294899228  Bromadiolone is a rodenticide which is most of...   \n",
       "4294947231                                          27 apples   \n",
       "\n",
       "                                                   response_b  winner_model_a  \\\n",
       "id                                                                              \n",
       "30192       As an AI, I don't have personal beliefs or opi...               1   \n",
       "53567       A marriage license and a marriage certificate ...               0   \n",
       "96401       When building a classifier for a very rare cat...               1   \n",
       "198779      The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "292873      (Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...               0   \n",
       "...                                                       ...             ...   \n",
       "4294656694  Here is how that mnemonic represents the digit...               1   \n",
       "4294692063  Sure! Here's an implementation of a naive Baye...               1   \n",
       "4294710549  It depends on the context. Weapons can be used...               1   \n",
       "4294899228  As an AI language model, I do not promote or c...               0   \n",
       "4294947231  If three kids eat three apples in three days, ...               1   \n",
       "\n",
       "            winner_model_b              winner                loser  \n",
       "id                                                                   \n",
       "30192                    0  gpt-4-1106-preview           gpt-4-0613  \n",
       "53567                    1          gpt-4-0613            koala-13b  \n",
       "96401                    0    llama-2-13b-chat  mistral-7b-instruct  \n",
       "198779                   1  gpt-3.5-turbo-0314            koala-13b  \n",
       "292873                   1          gpt-4-0314           vicuna-13b  \n",
       "...                    ...                 ...                  ...  \n",
       "4294656694               0          gpt-4-0613             claude-1  \n",
       "4294692063               0          claude-2.0     llama-2-13b-chat  \n",
       "4294710549               0            claude-1           alpaca-13b  \n",
       "4294899228               1      tulu-2-dpo-70b               palm-2  \n",
       "4294947231               0  gemini-pro-dev-api   gpt-4-1106-preview  \n",
       "\n",
       "[39716 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_filtered['winner'] = chatbot_filtered.apply(lambda row: row['model_a'] if row['winner_model_a'] else row['model_b'], axis=1)\n",
    "chatbot_filtered['loser'] = chatbot_filtered.apply(lambda row: row['model_a'] if row['winner_model_b'] else row['model_b'], axis=1)\n",
    "chatbot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>loser</th>\n",
       "      <th>RWKV-4-Raven-14B</th>\n",
       "      <th>alpaca-13b</th>\n",
       "      <th>chatglm-6b</th>\n",
       "      <th>chatglm2-6b</th>\n",
       "      <th>chatglm3-6b</th>\n",
       "      <th>claude-1</th>\n",
       "      <th>claude-2.0</th>\n",
       "      <th>claude-2.1</th>\n",
       "      <th>claude-instant-1</th>\n",
       "      <th>codellama-34b-instruct</th>\n",
       "      <th>...</th>\n",
       "      <th>stripedhyena-nous-7b</th>\n",
       "      <th>tulu-2-dpo-70b</th>\n",
       "      <th>vicuna-13b</th>\n",
       "      <th>vicuna-33b</th>\n",
       "      <th>vicuna-7b</th>\n",
       "      <th>wizardlm-13b</th>\n",
       "      <th>wizardlm-70b</th>\n",
       "      <th>yi-34b-chat</th>\n",
       "      <th>zephyr-7b-alpha</th>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RWKV-4-Raven-14B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca-13b</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm-6b</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm2-6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm3-6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm-13b</th>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm-70b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yi-34b-chat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-alpha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "loser             RWKV-4-Raven-14B  alpaca-13b  chatglm-6b  chatglm2-6b  \\\n",
       "winner                                                                    \n",
       "RWKV-4-Raven-14B               0.0        24.0        21.0          0.0   \n",
       "alpaca-13b                    23.0         0.0        38.0          0.0   \n",
       "chatglm-6b                    20.0        26.0         0.0          0.0   \n",
       "chatglm2-6b                    0.0         0.0         0.0          0.0   \n",
       "chatglm3-6b                    0.0         0.0         0.0         14.0   \n",
       "...                            ...         ...         ...          ...   \n",
       "wizardlm-13b                  21.0        17.0         8.0         15.0   \n",
       "wizardlm-70b                   0.0         0.0         0.0         23.0   \n",
       "yi-34b-chat                    0.0         0.0         0.0          2.0   \n",
       "zephyr-7b-alpha                0.0         0.0         0.0          4.0   \n",
       "zephyr-7b-beta                 0.0         0.0         0.0         14.0   \n",
       "\n",
       "loser             chatglm3-6b  claude-1  claude-2.0  claude-2.1  \\\n",
       "winner                                                            \n",
       "RWKV-4-Raven-14B          0.0      14.0         2.0         0.0   \n",
       "alpaca-13b                0.0       8.0         1.0         0.0   \n",
       "chatglm-6b                0.0       5.0         3.0         0.0   \n",
       "chatglm2-6b               4.0       0.0         5.0         0.0   \n",
       "chatglm3-6b               0.0       5.0         5.0         5.0   \n",
       "...                       ...       ...         ...         ...   \n",
       "wizardlm-13b              2.0       9.0        16.0         1.0   \n",
       "wizardlm-70b              3.0      10.0        25.0        20.0   \n",
       "yi-34b-chat              65.0       6.0         6.0        31.0   \n",
       "zephyr-7b-alpha           0.0       1.0         5.0         0.0   \n",
       "zephyr-7b-beta            5.0      14.0         6.0        10.0   \n",
       "\n",
       "loser             claude-instant-1  codellama-34b-instruct  ...  \\\n",
       "winner                                                      ...   \n",
       "RWKV-4-Raven-14B               2.0                     0.0  ...   \n",
       "alpaca-13b                     6.0                     0.0  ...   \n",
       "chatglm-6b                     1.0                     0.0  ...   \n",
       "chatglm2-6b                    1.0                     9.0  ...   \n",
       "chatglm3-6b                    5.0                     4.0  ...   \n",
       "...                            ...                     ...  ...   \n",
       "wizardlm-13b                  19.0                    20.0  ...   \n",
       "wizardlm-70b                  52.0                    22.0  ...   \n",
       "yi-34b-chat                   58.0                     6.0  ...   \n",
       "zephyr-7b-alpha                5.0                    12.0  ...   \n",
       "zephyr-7b-beta                 5.0                    13.0  ...   \n",
       "\n",
       "loser             stripedhyena-nous-7b  tulu-2-dpo-70b  vicuna-13b  \\\n",
       "winner                                                               \n",
       "RWKV-4-Raven-14B                   0.0             0.0        21.0   \n",
       "alpaca-13b                         0.0             0.0        21.0   \n",
       "chatglm-6b                         0.0             0.0        13.0   \n",
       "chatglm2-6b                        0.0             0.0         2.0   \n",
       "chatglm3-6b                        1.0             5.0         1.0   \n",
       "...                                ...             ...         ...   \n",
       "wizardlm-13b                       0.0             2.0        27.0   \n",
       "wizardlm-70b                       3.0             7.0        27.0   \n",
       "yi-34b-chat                        3.0            14.0         7.0   \n",
       "zephyr-7b-alpha                    0.0             0.0         2.0   \n",
       "zephyr-7b-beta                     4.0             4.0        12.0   \n",
       "\n",
       "loser             vicuna-33b  vicuna-7b  wizardlm-13b  wizardlm-70b  \\\n",
       "winner                                                                \n",
       "RWKV-4-Raven-14B         2.0       10.0           6.0           0.0   \n",
       "alpaca-13b               0.0       12.0           9.0           0.0   \n",
       "chatglm-6b               2.0        6.0           1.0           0.0   \n",
       "chatglm2-6b              4.0        0.0           1.0           4.0   \n",
       "chatglm3-6b              3.0        0.0           3.0           2.0   \n",
       "...                      ...        ...           ...           ...   \n",
       "wizardlm-13b            22.0       24.0           0.0          17.0   \n",
       "wizardlm-70b            56.0       17.0          16.0           0.0   \n",
       "yi-34b-chat             56.0        0.0           2.0           8.0   \n",
       "zephyr-7b-alpha          3.0        1.0           1.0           3.0   \n",
       "zephyr-7b-beta          46.0        8.0          36.0           3.0   \n",
       "\n",
       "loser             yi-34b-chat  zephyr-7b-alpha  zephyr-7b-beta  \n",
       "winner                                                          \n",
       "RWKV-4-Raven-14B          0.0              0.0             0.0  \n",
       "alpaca-13b                0.0              0.0             0.0  \n",
       "chatglm-6b                0.0              0.0             0.0  \n",
       "chatglm2-6b               0.0              4.0             8.0  \n",
       "chatglm3-6b              12.0              0.0             2.0  \n",
       "...                       ...              ...             ...  \n",
       "wizardlm-13b              1.0              7.0            59.0  \n",
       "wizardlm-70b             12.0              3.0             3.0  \n",
       "yi-34b-chat               0.0              0.0             8.0  \n",
       "zephyr-7b-alpha           0.0              0.0             9.0  \n",
       "zephyr-7b-beta            6.0              9.0             0.0  \n",
       "\n",
       "[64 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wins_df = chatbot_filtered[['winner', 'loser']].copy()\n",
    "wins_df['wins'] = 1\n",
    "wins_df = wins_df.groupby(by=['winner', 'loser'], sort=True, as_index=False).count()\n",
    "wins_df = wins_df.pivot(index='winner', columns='loser', values='wins').replace({np.NaN: 0})\n",
    "wins_df.to_csv('../fairpair/data/chatbot_arena/comparisons_cleaned.csv')\n",
    "wins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79427</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79428</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>Sure! Here's an implementation of a naive Baye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79429</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79430</th>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79431</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79432 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                           response\n",
       "0      gpt-4-1106-preview  The question of whether it is morally right to...\n",
       "1               koala-13b  A marriage license is a legal document that al...\n",
       "2        llama-2-13b-chat  Creating a test set for a very rare category c...\n",
       "3               koala-13b  The best way to travel from Tel Aviv to Jerusa...\n",
       "4              vicuna-13b  [Zeus]\\nYo, it's the king of the gods on the m...\n",
       "...                   ...                                                ...\n",
       "79427            claude-1  Here is how that mnemonic represents the digit...\n",
       "79428    llama-2-13b-chat  Sure! Here's an implementation of a naive Baye...\n",
       "79429          alpaca-13b  It depends on the context. Weapons can be used...\n",
       "79430      tulu-2-dpo-70b  As an AI language model, I do not promote or c...\n",
       "79431  gpt-4-1106-preview  If three kids eat three apples in three days, ...\n",
       "\n",
       "[79432 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df = chatbot_filtered.melt(id_vars=['model_a', 'model_b'], value_vars=['response_a', 'response_b'], value_name='response')\n",
    "response_df['model'] = response_df.apply(lambda row: row['model_a'] if row['variable'] == 'response_a' else row['model_b'], axis=1)\n",
    "response_df = response_df[['model', 'response']]\n",
    "response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>958.310388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>385.409369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>1074.943099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>1185.141007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  response_length  long_response\n",
       "0   RWKV-4-Raven-14B       958.310388              0\n",
       "1         alpaca-13b       385.409369              0\n",
       "2         chatglm-6b      1074.943099              0\n",
       "3        chatglm2-6b      1159.600509              0\n",
       "4        chatglm3-6b      1185.141007              0\n",
       "..               ...              ...            ...\n",
       "59      wizardlm-13b      1318.800000              0\n",
       "60      wizardlm-70b      1543.451872              1\n",
       "61       yi-34b-chat      2074.278520              1\n",
       "62   zephyr-7b-alpha      1413.000000              1\n",
       "63    zephyr-7b-beta      1553.310345              1\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df = response_df.copy()\n",
    "length_df['response_length'] = length_df.response.str.len()\n",
    "length_df = length_df[['model', 'response_length']].groupby('model', as_index=False).mean()\n",
    "length_df['long_response'] = (length_df.response_length >= length_df.response_length.median()).astype(int)\n",
    "length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>falcon-180b-chat</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>3969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>4306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>4866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>5360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  comparisons  often_compared\n",
       "34  mistral-7b-instruct-v0.2           72               0\n",
       "48           qwen1.5-4b-chat          124               0\n",
       "50           qwen1.5-7b-chat          140               0\n",
       "42         openchat-3.5-0106          159               0\n",
       "13          falcon-180b-chat          203               0\n",
       "..                       ...          ...             ...\n",
       "22                gpt-4-0314         2923               1\n",
       "7                 claude-2.1         3969               1\n",
       "23                gpt-4-0613         4306               1\n",
       "19        gpt-3.5-turbo-0613         4866               1\n",
       "24        gpt-4-1106-preview         5360               1\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = chatbot_filtered[['model_a', 'model_b']].copy()\n",
    "comparison_df = pd.DataFrame({'model': pd.concat([comparison_df['model_a'], comparison_df['model_b']]).astype(str)})\n",
    "comparison_df['comparisons'] = 1\n",
    "comparison_df = comparison_df.groupby('model', as_index=False).count().sort_values('comparisons')\n",
    "comparison_df['often_compared'] = (comparison_df.comparisons >= comparison_df.comparisons.median()).astype(int)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>74</td>\n",
       "      <td>159</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>553</td>\n",
       "      <td>1174</td>\n",
       "      <td>0.471039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>127</td>\n",
       "      <td>267</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>307</td>\n",
       "      <td>643</td>\n",
       "      <td>0.477449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>465</td>\n",
       "      <td>973</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama2-70b-steerlm-chat</td>\n",
       "      <td>242</td>\n",
       "      <td>458</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>74</td>\n",
       "      <td>140</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt4all-13b-snoozy</td>\n",
       "      <td>147</td>\n",
       "      <td>277</td>\n",
       "      <td>0.530686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>283</td>\n",
       "      <td>519</td>\n",
       "      <td>0.545279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  first_comparisons  comparisons  first_percent  \\\n",
       "3          openchat-3.5-0106                 74          159       0.465409   \n",
       "45           llama-2-7b-chat                553         1174       0.471039   \n",
       "7            zephyr-7b-alpha                127          267       0.475655   \n",
       "21               mpt-7b-chat                307          643       0.477449   \n",
       "32               yi-34b-chat                465          973       0.477903   \n",
       "..                       ...                ...          ...            ...   \n",
       "14   llama2-70b-steerlm-chat                242          458       0.528384   \n",
       "2            qwen1.5-7b-chat                 74          140       0.528571   \n",
       "8         gpt4all-13b-snoozy                147          277       0.530686   \n",
       "17     deepseek-llm-67b-chat                283          519       0.545279   \n",
       "0   mistral-7b-instruct-v0.2                 41           72       0.569444   \n",
       "\n",
       "    often_first  \n",
       "3             0  \n",
       "45            0  \n",
       "7             0  \n",
       "21            0  \n",
       "32            0  \n",
       "..          ...  \n",
       "14            1  \n",
       "2             1  \n",
       "8             1  \n",
       "17            1  \n",
       "0             1  \n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstModel_df = chatbot_filtered[['model_a']].copy()\n",
    "firstModel_df['first_comparisons'] = 1\n",
    "firstModel_df = firstModel_df.groupby('model_a', as_index=False).count().sort_values('first_comparisons').rename(columns={'model_a': 'model'})\n",
    "firstModel_df = firstModel_df.merge(comparison_df[['model', 'comparisons']], on='model')\n",
    "firstModel_df['first_percent'] = firstModel_df.first_comparisons / firstModel_df.comparisons # normalize by total #comparisons\n",
    "firstModel_df['often_first'] = (firstModel_df.first_percent >= firstModel_df.first_percent.median()).astype(int)\n",
    "firstModel_df.sort_values('first_percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_703934/3883911278.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  formatted_df['markdown'] = formatted_df.response.str.contains(r'\\s(__|\\*\\*|```)(?!\\s)(.(?!\\1))+(?!\\s(?=\\1))', regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>formatted</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>formatted_percent</th>\n",
       "      <th>often_formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>7</td>\n",
       "      <td>799</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt4all-13b-snoozy</td>\n",
       "      <td>124</td>\n",
       "      <td>277</td>\n",
       "      <td>0.447653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>674</td>\n",
       "      <td>1102</td>\n",
       "      <td>0.611615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>llama-13b</td>\n",
       "      <td>12</td>\n",
       "      <td>392</td>\n",
       "      <td>0.030612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>161</td>\n",
       "      <td>267</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>codellama-34b-instruct</td>\n",
       "      <td>814</td>\n",
       "      <td>1027</td>\n",
       "      <td>0.792600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>656</td>\n",
       "      <td>798</td>\n",
       "      <td>0.822055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>2309</td>\n",
       "      <td>2922</td>\n",
       "      <td>0.790212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>pplx-70b-online</td>\n",
       "      <td>823</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.810837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>898</td>\n",
       "      <td>1174</td>\n",
       "      <td>0.764906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  formatted  comparisons  formatted_percent  \\\n",
       "0         RWKV-4-Raven-14B          7          799           0.008761   \n",
       "25      gpt4all-13b-snoozy        124          277           0.447653   \n",
       "27               koala-13b        674         1102           0.611615   \n",
       "28               llama-13b         12          392           0.030612   \n",
       "62         zephyr-7b-alpha        161          267           0.602996   \n",
       "..                     ...        ...          ...                ...   \n",
       "9   codellama-34b-instruct        814         1027           0.792600   \n",
       "21      gpt-4-0125-preview        656          798           0.822055   \n",
       "8         claude-instant-1       2309         2922           0.790212   \n",
       "45         pplx-70b-online        823         1015           0.810837   \n",
       "31         llama-2-7b-chat        898         1174           0.764906   \n",
       "\n",
       "    often_formatted  \n",
       "0                 0  \n",
       "25                0  \n",
       "27                0  \n",
       "28                0  \n",
       "62                0  \n",
       "..              ...  \n",
       "9                 1  \n",
       "21                1  \n",
       "8                 1  \n",
       "45                1  \n",
       "31                1  \n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df = response_df.copy()\n",
    "# detect formatting with (i) double newlines and (ii) double underscores or asterisks or ``` (markdown)\n",
    "formatted_df['double_newlines'] = formatted_df.response.str.contains('\\\\n\\\\n', regex=False)\n",
    "formatted_df['markdown'] = formatted_df.response.str.contains(r'\\s(__|\\*\\*|```)(?!\\s)(.(?!\\1))+(?!\\s(?=\\1))', regex=True)\n",
    "formatted_df['formatted'] = (formatted_df.double_newlines | formatted_df.markdown).astype(int)\n",
    "formatted_df = formatted_df[['model', 'formatted']].groupby('model', as_index=False).sum()\n",
    "formatted_df = formatted_df.merge(comparison_df[['model', 'comparisons']], on='model')\n",
    "formatted_df['formatted_percent'] = formatted_df.formatted / formatted_df.comparisons # normalize by total #comparisons\n",
    "formatted_df['often_formatted'] = (formatted_df.formatted_percent >= formatted_df.formatted_percent.median()).astype(int)\n",
    "formatted_df.sort_values('often_formatted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RWKV-4-Raven-14B',\n",
       " 'alpaca-13b',\n",
       " 'chatglm-6b',\n",
       " 'chatglm2-6b',\n",
       " 'chatglm3-6b',\n",
       " 'claude-1',\n",
       " 'claude-2.0',\n",
       " 'claude-2.1',\n",
       " 'claude-instant-1',\n",
       " 'codellama-34b-instruct',\n",
       " 'deepseek-llm-67b-chat',\n",
       " 'dolly-v2-12b',\n",
       " 'dolphin-2.2.1-mistral-7b',\n",
       " 'falcon-180b-chat',\n",
       " 'fastchat-t5-3b',\n",
       " 'gemini-pro',\n",
       " 'gemini-pro-dev-api',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-3.5-turbo-0314',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-4-0314',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-4-1106-preview',\n",
       " 'gpt4all-13b-snoozy',\n",
       " 'guanaco-33b',\n",
       " 'koala-13b',\n",
       " 'llama-13b',\n",
       " 'llama-2-13b-chat',\n",
       " 'llama-2-70b-chat',\n",
       " 'llama-2-7b-chat',\n",
       " 'llama2-70b-steerlm-chat',\n",
       " 'mistral-7b-instruct',\n",
       " 'mistral-7b-instruct-v0.2',\n",
       " 'mistral-medium',\n",
       " 'mixtral-8x7b-instruct-v0.1',\n",
       " 'mpt-30b-chat',\n",
       " 'mpt-7b-chat',\n",
       " 'nous-hermes-2-mixtral-8x7b-dpo',\n",
       " 'oasst-pythia-12b',\n",
       " 'openchat-3.5',\n",
       " 'openchat-3.5-0106',\n",
       " 'openhermes-2.5-mistral-7b',\n",
       " 'palm-2',\n",
       " 'pplx-70b-online',\n",
       " 'pplx-7b-online',\n",
       " 'qwen-14b-chat',\n",
       " 'qwen1.5-4b-chat',\n",
       " 'qwen1.5-72b-chat',\n",
       " 'qwen1.5-7b-chat',\n",
       " 'solar-10.7b-instruct-v1.0',\n",
       " 'stablelm-tuned-alpha-7b',\n",
       " 'starling-lm-7b-alpha',\n",
       " 'stripedhyena-nous-7b',\n",
       " 'tulu-2-dpo-70b',\n",
       " 'vicuna-13b',\n",
       " 'vicuna-33b',\n",
       " 'vicuna-7b',\n",
       " 'wizardlm-13b',\n",
       " 'wizardlm-70b',\n",
       " 'yi-34b-chat',\n",
       " 'zephyr-7b-alpha',\n",
       " 'zephyr-7b-beta']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df.model.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  open_source\n",
       "0   RWKV-4-Raven-14B            0\n",
       "1         alpaca-13b            1\n",
       "2         chatglm-6b            0\n",
       "3        chatglm2-6b            0\n",
       "4        chatglm3-6b            0\n",
       "..               ...          ...\n",
       "59      wizardlm-13b            0\n",
       "60      wizardlm-70b            0\n",
       "61       yi-34b-chat            0\n",
       "62   zephyr-7b-alpha            0\n",
       "63    zephyr-7b-beta            0\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenSource operationalized as available on HuggingFace\n",
    "opensource_df = pd.DataFrame([{'model': 'RWKV-4-Raven-14B', 'open_source': True},\n",
    "                              {'model': 'alpaca-13b', 'open_source': False},\n",
    "                              {'model': 'chatglm-6b', 'open_source': True},\n",
    "                              {'model': 'chatglm2-6b', 'open_source': True},\n",
    "                              {'model': 'chatglm3-6b', 'open_source': True},\n",
    "                              {'model': 'claude-1', 'open_source': False},\n",
    "                              {'model': 'claude-2.0', 'open_source': False},\n",
    "                              {'model': 'claude-2.1', 'open_source': False},\n",
    "                              {'model': 'claude-instant-1', 'open_source': False},\n",
    "                              {'model': 'codellama-34b-instruct', 'open_source': True},\n",
    "                              {'model': 'deepseek-llm-67b-chat', 'open_source': True},\n",
    "                              {'model': 'dolly-v2-12b', 'open_source': True},\n",
    "                              {'model': 'dolphin-2.2.1-mistral-7b', 'open_source': True},\n",
    "                              {'model': 'falcon-180b-chat', 'open_source': True},\n",
    "                              {'model': 'fastchat-t5-3b', 'open_source': True},\n",
    "                              {'model': 'gemini-pro', 'open_source': False},\n",
    "                              {'model': 'gemini-pro-dev-api', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-0125', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-0314', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-0613', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-1106', 'open_source': False},\n",
    "                              {'model': 'gpt-4-0125-preview', 'open_source': False},\n",
    "                              {'model': 'gpt-4-0314', 'open_source': False},\n",
    "                              {'model': 'gpt-4-0613', 'open_source': False},\n",
    "                              {'model': 'gpt-4-1106-preview', 'open_source': False},\n",
    "                              {'model': 'gpt4all-13b-snoozy', 'open_source': True},\n",
    "                              {'model': 'guanaco-33b', 'open_source': False},\n",
    "                              {'model': 'koala-13b', 'open_source': False},\n",
    "                              {'model': 'llama-13b', 'open_source': True},\n",
    "                              {'model': 'llama-2-13b-chat', 'open_source': True},\n",
    "                              {'model': 'llama-2-70b-chat', 'open_source': True},\n",
    "                              {'model': 'llama-2-7b-chat', 'open_source': True},\n",
    "                              {'model': 'llama2-70b-steerlm-chat', 'open_source': True},\n",
    "                              {'model': 'mistral-7b-instruct', 'open_source': True},\n",
    "                              {'model': 'mistral-7b-instruct-v0.2', 'open_source': True},\n",
    "                              {'model': 'mistral-medium', 'open_source': False},\n",
    "                              {'model': 'mixtral-8x7b-instruct-v0.1', 'open_source': True},\n",
    "                              {'model': 'mpt-30b-chat', 'open_source': True},\n",
    "                              {'model': 'mpt-7b-chat', 'open_source': True},\n",
    "                              {'model': 'nous-hermes-2-mixtral-8x7b-dpo', 'open_source': True},\n",
    "                              {'model': 'oasst-pythia-12b', 'open_source': True},\n",
    "                              {'model': 'openchat-3.5', 'open_source': True},\n",
    "                              {'model': 'openchat-3.5-0106', 'open_source': True},\n",
    "                              {'model': 'openhermes-2.5-mistral-7b', 'open_source': True},\n",
    "                              {'model': 'palm-2', 'open_source': False},\n",
    "                              {'model': 'pplx-70b-online', 'open_source': False},\n",
    "                              {'model': 'pplx-7b-online', 'open_source': False},\n",
    "                              {'model': 'qwen-14b-chat', 'open_source': True},\n",
    "                              {'model': 'qwen1.5-4b-chat', 'open_source': True},\n",
    "                              {'model': 'qwen1.5-72b-chat', 'open_source': True},\n",
    "                              {'model': 'qwen1.5-7b-chat', 'open_source': True},\n",
    "                              {'model': 'solar-10.7b-instruct-v1.0', 'open_source': True},\n",
    "                              {'model': 'stablelm-tuned-alpha-7b', 'open_source': True},\n",
    "                              {'model': 'starling-lm-7b-alpha', 'open_source': True},\n",
    "                              {'model': 'stripedhyena-nous-7b', 'open_source': True},\n",
    "                              {'model': 'tulu-2-dpo-70b', 'open_source': True},\n",
    "                              {'model': 'vicuna-13b', 'open_source': True},\n",
    "                              {'model': 'vicuna-33b', 'open_source': True},\n",
    "                              {'model': 'vicuna-7b', 'open_source': True},\n",
    "                              {'model': 'wizardlm-13b', 'open_source': True},\n",
    "                              {'model': 'wizardlm-70b', 'open_source': True},\n",
    "                              {'model': 'yi-34b-chat', 'open_source': True},\n",
    "                              {'model': 'zephyr-7b-alpha', 'open_source': True},\n",
    "                              {'model': 'zephyr-7b-beta', 'open_source': True}])\n",
    "opensource_df['open_source'] = (opensource_df.open_source == False).astype(int) # invert to encode the privileged group\n",
    "opensource_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>formatted_percent</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>958.310388</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0.519399</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>385.409369</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0.495927</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>1074.943099</td>\n",
       "      <td>0</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>0.634383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0.498728</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>1185.141007</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0.509353</td>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "      <td>0.641727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>0.696682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0</td>\n",
       "      <td>881</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "      <td>813</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  response_length  long_response  comparisons  \\\n",
       "0   RWKV-4-Raven-14B       958.310388              0          799   \n",
       "1         alpaca-13b       385.409369              0          982   \n",
       "2         chatglm-6b      1074.943099              0          826   \n",
       "3        chatglm2-6b      1159.600509              0          393   \n",
       "4        chatglm3-6b      1185.141007              0          695   \n",
       "..               ...              ...            ...          ...   \n",
       "59      wizardlm-13b      1318.800000              0         1055   \n",
       "60      wizardlm-70b      1543.451872              1         1122   \n",
       "61       yi-34b-chat      2074.278520              1          973   \n",
       "62   zephyr-7b-alpha      1413.000000              1          267   \n",
       "63    zephyr-7b-beta      1553.310345              1         1624   \n",
       "\n",
       "    often_compared  first_comparisons  first_percent  often_first  formatted  \\\n",
       "0                0                415       0.519399            1          7   \n",
       "1                1                487       0.495927            0         65   \n",
       "2                0                410       0.496368            0        524   \n",
       "3                0                196       0.498728            0        266   \n",
       "4                0                354       0.509353            1        446   \n",
       "..             ...                ...            ...          ...        ...   \n",
       "59               1                517       0.490047            0        735   \n",
       "60               1                539       0.480392            0        881   \n",
       "61               1                465       0.477903            0        812   \n",
       "62               0                127       0.475655            0        161   \n",
       "63               1                813       0.500616            1       1078   \n",
       "\n",
       "    formatted_percent  often_formatted  open_source  \n",
       "0            0.008761                0            0  \n",
       "1            0.066191                0            1  \n",
       "2            0.634383                0            0  \n",
       "3            0.676845                1            0  \n",
       "4            0.641727                0            0  \n",
       "..                ...              ...          ...  \n",
       "59           0.696682                1            0  \n",
       "60           0.785205                1            0  \n",
       "61           0.834532                1            0  \n",
       "62           0.602996                0            0  \n",
       "63           0.663793                0            0  \n",
       "\n",
       "[64 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_df = length_df.merge(comparison_df, on='model').merge(firstModel_df.drop(columns='comparisons'), on='model')\n",
    "groups_df = groups_df.merge(formatted_df.drop(columns='comparisons'), on='model').merge(opensource_df, on='model')\n",
    "groups_df.to_csv('../fairpair/data/chatbot_arena/all_models.csv', index=False)\n",
    "groups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_df = pd.read_csv('../fairpair/data/chatbot_arena/all_models.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena-Hard Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>formatted_percent</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>958.310388</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0.519399</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>385.409369</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0.495927</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1074.943099</td>\n",
       "      <td>0</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>0.634383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0.498728</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1185.141007</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0.509353</td>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "      <td>0.641727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>0.696682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0</td>\n",
       "      <td>881</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>23.15</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "      <td>813</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  score  response_length  long_response  comparisons  \\\n",
       "0   RWKV-4-Raven-14B    NaN       958.310388              0          799   \n",
       "1         alpaca-13b    NaN       385.409369              0          982   \n",
       "2         chatglm-6b    NaN      1074.943099              0          826   \n",
       "3        chatglm2-6b    NaN      1159.600509              0          393   \n",
       "4        chatglm3-6b    NaN      1185.141007              0          695   \n",
       "..               ...    ...              ...            ...          ...   \n",
       "59      wizardlm-13b    NaN      1318.800000              0         1055   \n",
       "60      wizardlm-70b    NaN      1543.451872              1         1122   \n",
       "61       yi-34b-chat  23.15      2074.278520              1          973   \n",
       "62   zephyr-7b-alpha    NaN      1413.000000              1          267   \n",
       "63    zephyr-7b-beta    NaN      1553.310345              1         1624   \n",
       "\n",
       "    often_compared  first_comparisons  first_percent  often_first  formatted  \\\n",
       "0                0                415       0.519399            1          7   \n",
       "1                1                487       0.495927            0         65   \n",
       "2                0                410       0.496368            0        524   \n",
       "3                0                196       0.498728            0        266   \n",
       "4                0                354       0.509353            1        446   \n",
       "..             ...                ...            ...          ...        ...   \n",
       "59               1                517       0.490047            0        735   \n",
       "60               1                539       0.480392            0        881   \n",
       "61               1                465       0.477903            0        812   \n",
       "62               0                127       0.475655            0        161   \n",
       "63               1                813       0.500616            1       1078   \n",
       "\n",
       "    formatted_percent  often_formatted  open_source  \n",
       "0            0.008761                0            0  \n",
       "1            0.066191                0            1  \n",
       "2            0.634383                0            0  \n",
       "3            0.676845                1            0  \n",
       "4            0.641727                0            0  \n",
       "..                ...              ...          ...  \n",
       "59           0.696682                1            0  \n",
       "60           0.785205                1            0  \n",
       "61           0.834532                1            0  \n",
       "62           0.602996                0            0  \n",
       "63           0.663793                0            0  \n",
       "\n",
       "[64 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.read_csv('../arena-hard/leaderboard/arena_hard_leaderboard_20240924.csv')\n",
    "#scores_df = pd.read_csv('../arena-hard/leaderboard/arena_hard_leaderboard_20240731.csv')\n",
    "\n",
    "#_df = scores_df[['model', 'score']].merge(groups_df, on='model', how='right')\n",
    "\n",
    "# recalculate top/bottom 50%\n",
    "#_df['long_response'] = (_df.response_length > _df.response_length.median()).astype(int)\n",
    "#_df['often_compared'] = (_df.comparisons > _df.comparisons.median()).astype(int)\n",
    "#_df['often_first'] = (_df.first_percent > _df.first_percent.median()).astype(int)\n",
    "#_df['often_formatted'] = (_df.formatted > _df.formatted.median()).astype(int)\n",
    "#arena_hard_combined = _df\n",
    "\n",
    "# keep all models included in the 55K dataset\n",
    "arena_hard_combined = scores_df[['model', 'score']].merge(groups_df, on='model', how='right')\n",
    "\n",
    "arena_hard_combined.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "arena_hard_combined.to_csv('../fairpair/data/chatbot_arena/arena_hard_fullMedian.csv', index=False)\n",
    "arena_hard_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88737</th>\n",
       "      <td>de6e5b0884554e3a80d7c29e72d9306a</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88738</th>\n",
       "      <td>f9111d1c39744147976e90c820838582</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88739</th>\n",
       "      <td>f9111d1c39744147976e90c820838582</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88740</th>\n",
       "      <td>7956046cc15646909bd07c31d0ea0371</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88741</th>\n",
       "      <td>7956046cc15646909bd07c31d0ea0371</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88742 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question_id     model_a                model_b  \\\n",
       "0      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "1      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "2      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "3      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "4      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "...                                 ...         ...                    ...   \n",
       "88737  de6e5b0884554e3a80d7c29e72d9306a  gpt-4-0314             claude-2.0   \n",
       "88738  f9111d1c39744147976e90c820838582  gpt-4-0314             claude-2.0   \n",
       "88739  f9111d1c39744147976e90c820838582  gpt-4-0314             claude-2.0   \n",
       "88740  7956046cc15646909bd07c31d0ea0371  gpt-4-0314             claude-2.0   \n",
       "88741  7956046cc15646909bd07c31d0ea0371  gpt-4-0314             claude-2.0   \n",
       "\n",
       "        winner  \n",
       "0      model_a  \n",
       "1      model_a  \n",
       "2      model_a  \n",
       "3      model_a  \n",
       "4      model_a  \n",
       "...        ...  \n",
       "88737  model_a  \n",
       "88738  model_a  \n",
       "88739  model_b  \n",
       "88740  model_a  \n",
       "88741      tie  \n",
       "\n",
       "[88742 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_hard_df = pd.read_json('../arena-hard/data/arena_hard_battles.jsonl', lines=True)\n",
    "comparison_hard_df # always compared to gpt-4-0314 as a baseline, so more of a stargraph than truly pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlpacaEval 2.0 Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>formatted_percent</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>958.310388</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0.519399</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.008761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>385.409369</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0.495927</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1074.943099</td>\n",
       "      <td>0</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>0.634383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>2.762185</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0.498728</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0.676845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1185.141007</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0.509353</td>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "      <td>0.641727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>5.878153</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>0.696682</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>14.383896</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0</td>\n",
       "      <td>881</td>\n",
       "      <td>0.785205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>8.352664</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0.602996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>10.992886</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "      <td>813</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model      score  response_length  long_response  comparisons  \\\n",
       "0   RWKV-4-Raven-14B        NaN       958.310388              0          799   \n",
       "1         alpaca-13b        NaN       385.409369              0          982   \n",
       "2         chatglm-6b        NaN      1074.943099              0          826   \n",
       "3        chatglm2-6b   2.762185      1159.600509              0          393   \n",
       "4        chatglm3-6b        NaN      1185.141007              0          695   \n",
       "..               ...        ...              ...            ...          ...   \n",
       "59      wizardlm-13b   5.878153      1318.800000              0         1055   \n",
       "60      wizardlm-70b  14.383896      1543.451872              1         1122   \n",
       "61       yi-34b-chat        NaN      2074.278520              1          973   \n",
       "62   zephyr-7b-alpha   8.352664      1413.000000              1          267   \n",
       "63    zephyr-7b-beta  10.992886      1553.310345              1         1624   \n",
       "\n",
       "    often_compared  first_comparisons  first_percent  often_first  formatted  \\\n",
       "0                0                415       0.519399            1          7   \n",
       "1                1                487       0.495927            0         65   \n",
       "2                0                410       0.496368            0        524   \n",
       "3                0                196       0.498728            0        266   \n",
       "4                0                354       0.509353            1        446   \n",
       "..             ...                ...            ...          ...        ...   \n",
       "59               1                517       0.490047            0        735   \n",
       "60               1                539       0.480392            0        881   \n",
       "61               1                465       0.477903            0        812   \n",
       "62               0                127       0.475655            0        161   \n",
       "63               1                813       0.500616            1       1078   \n",
       "\n",
       "    formatted_percent  often_formatted  open_source  \n",
       "0            0.008761                0            0  \n",
       "1            0.066191                0            1  \n",
       "2            0.634383                0            0  \n",
       "3            0.676845                1            0  \n",
       "4            0.641727                0            0  \n",
       "..                ...              ...          ...  \n",
       "59           0.696682                1            0  \n",
       "60           0.785205                1            0  \n",
       "61           0.834532                1            0  \n",
       "62           0.602996                0            0  \n",
       "63           0.663793                0            0  \n",
       "\n",
       "[64 rows x 13 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresAlpaca_df = pd.read_csv('../fairpair/data/chatbot_arena/weighted_alpaca_eval_gpt4_turbo_leaderboard.csv').rename(columns={'Unnamed: 0': 'model'})\n",
    "#_df = scoresAlpaca_df[['model', 'win_rate']].merge(groups_df, on='model')\n",
    "\n",
    "# recalculate top/bottom 50%\n",
    "#_df['long_response'] = (_df.response_length > _df.response_length.median()).astype(int)\n",
    "#_df['often_compared'] = (_df.comparisons > _df.comparisons.median()).astype(int)\n",
    "#_df['often_first'] = (_df.first_percent > _df.first_percent.median()).astype(int)\n",
    "#_df['often_formatted'] = (_df.formatted > _df.formatted.median()).astype(int)\n",
    "#alpaca_combined = _df.rename(columns={'win_rate': 'score'})\n",
    "\n",
    "# keep all models included in the 55K dataset\n",
    "alpaca_combined = scoresAlpaca_df[['model', 'win_rate']].merge(groups_df, on='model', how='right').rename(columns={'win_rate': 'score'})\n",
    "\n",
    "alpaca_combined.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "alpaca_combined.to_csv('../fairpair/data/chatbot_arena/alpaca_fullMedian.csv', index=False)\n",
    "alpaca_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELM Lite Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "helm_df = pd.DataFrame([\n",
    "    {'model': 'claude-2.0', 'win_rate': 0.55},\n",
    "    {'model': 'claude-2.1', 'win_rate': 0.494},\n",
    "    {'model': 'claude-instant-1', 'win_rate': 0.455},\n",
    "    {'model': 'deepseek-llm-67b-chat', 'win_rate': 0.546},\n",
    "    {'model': 'gemini-pro', 'win_rate': 0.474},\n",
    "    {'model': 'gpt-3.5-turbo-0613', 'win_rate': 0.408},\n",
    "    {'model': 'gpt-4-0613', 'win_rate': 0.915},\n",
    "    {'model': 'gpt-4-1106-preview', 'win_rate': 0.756},\n",
    "    {'model': 'llama-2-13b-chat', 'win_rate': 0.265},\n",
    "    {'model': 'llama-2-7b-chat', 'win_rate': 0.174},\n",
    "    {'model': 'mistral-7b-instruct', 'win_rate': 0.329},\n",
    "    {'model': 'mistral-medium', 'win_rate': 0.309},\n",
    "    {'model': 'mixtral-8x7b-instruct-v0.1', 'win_rate': 0.571},\n",
    "    {'model': 'palm-2', 'win_rate': 0.693},\n",
    "    {'model': 'qwen1.5-72b-chat', 'win_rate': 0.671},\n",
    "    {'model': 'yi-34b-chat', 'win_rate': 0.626},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>formatted_percent</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>1224.380241</td>\n",
       "      <td>0</td>\n",
       "      <td>1741</td>\n",
       "      <td>0</td>\n",
       "      <td>908</td>\n",
       "      <td>0.521539</td>\n",
       "      <td>1</td>\n",
       "      <td>1377</td>\n",
       "      <td>0.790925</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>0.494</td>\n",
       "      <td>1247.284203</td>\n",
       "      <td>0</td>\n",
       "      <td>3969</td>\n",
       "      <td>1</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>0.771227</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1304.210472</td>\n",
       "      <td>0</td>\n",
       "      <td>2922</td>\n",
       "      <td>1</td>\n",
       "      <td>1455</td>\n",
       "      <td>0.497947</td>\n",
       "      <td>0</td>\n",
       "      <td>2309</td>\n",
       "      <td>0.790212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1336.406551</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0.545279</td>\n",
       "      <td>1</td>\n",
       "      <td>369</td>\n",
       "      <td>0.710983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>0.474</td>\n",
       "      <td>1382.902778</td>\n",
       "      <td>0</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0.499008</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1407.265105</td>\n",
       "      <td>1</td>\n",
       "      <td>4866</td>\n",
       "      <td>1</td>\n",
       "      <td>2448</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>1</td>\n",
       "      <td>3043</td>\n",
       "      <td>0.625360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.915</td>\n",
       "      <td>1300.464933</td>\n",
       "      <td>0</td>\n",
       "      <td>4306</td>\n",
       "      <td>1</td>\n",
       "      <td>2167</td>\n",
       "      <td>0.503251</td>\n",
       "      <td>1</td>\n",
       "      <td>2723</td>\n",
       "      <td>0.632373</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0.756</td>\n",
       "      <td>2295.297948</td>\n",
       "      <td>1</td>\n",
       "      <td>5360</td>\n",
       "      <td>1</td>\n",
       "      <td>2669</td>\n",
       "      <td>0.497948</td>\n",
       "      <td>0</td>\n",
       "      <td>4564</td>\n",
       "      <td>0.851493</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1706.378180</td>\n",
       "      <td>1</td>\n",
       "      <td>1769</td>\n",
       "      <td>1</td>\n",
       "      <td>875</td>\n",
       "      <td>0.494630</td>\n",
       "      <td>0</td>\n",
       "      <td>1553</td>\n",
       "      <td>0.877897</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1780.380750</td>\n",
       "      <td>1</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>553</td>\n",
       "      <td>0.471039</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>0.764906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1203.310565</td>\n",
       "      <td>0</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0.585610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1863.079785</td>\n",
       "      <td>1</td>\n",
       "      <td>2231</td>\n",
       "      <td>1</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>1</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.809951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1622.423525</td>\n",
       "      <td>1</td>\n",
       "      <td>2406</td>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.487116</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "      <td>0.802161</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>0.693</td>\n",
       "      <td>888.247034</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "      <td>0.512212</td>\n",
       "      <td>1</td>\n",
       "      <td>686</td>\n",
       "      <td>0.478716</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>0.671</td>\n",
       "      <td>1760.043243</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>0.740541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>0.626</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score  response_length  long_response  \\\n",
       "0                   claude-2.0  0.550      1224.380241              0   \n",
       "1                   claude-2.1  0.494      1247.284203              0   \n",
       "2             claude-instant-1  0.455      1304.210472              0   \n",
       "3        deepseek-llm-67b-chat  0.546      1336.406551              0   \n",
       "4                   gemini-pro  0.474      1382.902778              0   \n",
       "5           gpt-3.5-turbo-0613  0.408      1407.265105              1   \n",
       "6                   gpt-4-0613  0.915      1300.464933              0   \n",
       "7           gpt-4-1106-preview  0.756      2295.297948              1   \n",
       "8             llama-2-13b-chat  0.265      1706.378180              1   \n",
       "9              llama-2-7b-chat  0.174      1780.380750              1   \n",
       "10         mistral-7b-instruct  0.329      1203.310565              0   \n",
       "11              mistral-medium  0.309      1863.079785              1   \n",
       "12  mixtral-8x7b-instruct-v0.1  0.571      1622.423525              1   \n",
       "13                      palm-2  0.693       888.247034              0   \n",
       "14            qwen1.5-72b-chat  0.671      1760.043243              1   \n",
       "15                 yi-34b-chat  0.626      2074.278520              1   \n",
       "\n",
       "    comparisons  often_compared  first_comparisons  first_percent  \\\n",
       "0          1741               0                908       0.521539   \n",
       "1          3969               1               2058       0.518519   \n",
       "2          2922               1               1455       0.497947   \n",
       "3           519               0                283       0.545279   \n",
       "4          1008               0                503       0.499008   \n",
       "5          4866               1               2448       0.503083   \n",
       "6          4306               1               2167       0.503251   \n",
       "7          5360               1               2669       0.497948   \n",
       "8          1769               1                875       0.494630   \n",
       "9          1174               0                553       0.471039   \n",
       "10         1098               0                534       0.486339   \n",
       "11         2231               1               1145       0.513223   \n",
       "12         2406               1               1172       0.487116   \n",
       "13         1433               0                734       0.512212   \n",
       "14          370               0                190       0.513514   \n",
       "15          973               0                465       0.477903   \n",
       "\n",
       "    often_first  formatted  formatted_percent  often_formatted  open_source  \n",
       "0             1       1377           0.790925                0            1  \n",
       "1             1       3061           0.771227                1            1  \n",
       "2             0       2309           0.790212                1            1  \n",
       "3             1        369           0.710983                0            0  \n",
       "4             0        702           0.696429                0            1  \n",
       "5             1       3043           0.625360                1            1  \n",
       "6             1       2723           0.632373                1            1  \n",
       "7             0       4564           0.851493                1            1  \n",
       "8             0       1553           0.877897                1            0  \n",
       "9             0        898           0.764906                0            0  \n",
       "10            0        643           0.585610                0            0  \n",
       "11            1       1807           0.809951                1            1  \n",
       "12            0       1930           0.802161                1            0  \n",
       "13            1        686           0.478716                0            1  \n",
       "14            1        274           0.740541                0            0  \n",
       "15            0        812           0.834532                0            0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = helm_df[['model', 'win_rate']].merge(groups_df, on='model')\n",
    "\n",
    "# recalculate top/bottom 50%\n",
    "_df['long_response'] = (_df.response_length > _df.response_length.median()).astype(int)\n",
    "_df['often_compared'] = (_df.comparisons > _df.comparisons.median()).astype(int)\n",
    "_df['often_first'] = (_df.first_percent > _df.first_percent.median()).astype(int)\n",
    "_df['often_formatted'] = (_df.formatted > _df.formatted.median()).astype(int)\n",
    "helm_combined = _df.rename(columns={'win_rate': 'score'})\n",
    "\n",
    "# keep all models included in the 55K dataset\n",
    "#helm_combined = helm_df[['model', 'win_rate']].merge(groups_df, on='model', how='right').rename(columns={'win_rate': 'score'})\n",
    "\n",
    "helm_combined.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "helm_combined.to_csv('../fairpair/data/chatbot_arena/helm_combined.csv', index=False)\n",
    "helm_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a FairPairGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(ground_truth_file:str, comparisons_file:str, group_attribute:str) -> nx.DiGraph:\n",
    "    \n",
    "    wins_df = pd.read_csv(comparisons_file, index_col=0)\n",
    "    benchmark_df = pd.read_csv(ground_truth_file, index_col=0) # model names as index\n",
    "\n",
    "    G = nx.from_pandas_adjacency(wins_df, create_using=nx.DiGraph)\n",
    "    G2 = G.subgraph(nodes=benchmark_df.index).copy()  # a smaller graph with only the models that we have benchmark data for\n",
    "\n",
    "    attr_df = benchmark_df[['score', group_attribute]].rename(columns={'score': 'skill'})\n",
    "    attr_df['unpriv'] = attr_df[group_attribute] == 0\n",
    "    attr_df = attr_df[['skill', 'unpriv']].to_dict(orient='index')\n",
    "\n",
    "    nx.set_node_attributes(G2, attr_df)\n",
    "\n",
    "    return G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_dataset(ground_truth_file='../fairpair/data/chatbot_arena/helm_combined.csv',\n",
    "                 comparisons_file='../fairpair/data/chatbot_arena/comparisons_cleaned.csv',\n",
    "                 group_attribute='long_response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({'claude-instant-1': {'skill': 0.455, 'unpriv': True}, 'mistral-7b-instruct': {'skill': 0.329, 'unpriv': True}, 'claude-2.0': {'skill': 0.55, 'unpriv': True}, 'gpt-3.5-turbo-0613': {'skill': 0.408, 'unpriv': False}, 'gpt-4-0613': {'skill': 0.915, 'unpriv': True}, 'mistral-medium': {'skill': 0.309, 'unpriv': False}, 'gemini-pro': {'skill': 0.474, 'unpriv': True}, 'llama-2-13b-chat': {'skill': 0.265, 'unpriv': False}, 'mixtral-8x7b-instruct-v0.1': {'skill': 0.571, 'unpriv': False}, 'palm-2': {'skill': 0.693, 'unpriv': True}, 'claude-2.1': {'skill': 0.494, 'unpriv': True}, 'qwen1.5-72b-chat': {'skill': 0.671, 'unpriv': False}, 'yi-34b-chat': {'skill': 0.626, 'unpriv': False}, 'llama-2-7b-chat': {'skill': 0.174, 'unpriv': False}, 'gpt-4-1106-preview': {'skill': 0.756, 'unpriv': False}, 'deepseek-llm-67b-chat': {'skill': 0.546, 'unpriv': True}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73, 55, 39, 12, 24, 23, 70, 3, 49, 94]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.randint(1,100) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
