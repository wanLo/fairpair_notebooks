{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Arena 55K Pairwise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_df = pd.read_csv(\"hf://datasets/lmsys/lmsys-arena-human-preference-55k/train.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_filtered = chatbot_df[chatbot_df.winner_tie == 0].drop(columns='winner_tie') # remove ties\n",
    "#chatbot_filtered = chatbot_filtered[~chatbot_filtered.prompt.str.startswith('[\"System')] # remove special tasks?\n",
    "chatbot_filtered['prompt'] = chatbot_filtered.prompt.str[2:-2] # cleanup prompt\n",
    "chatbot_filtered['response_a'] = chatbot_filtered.response_a.str[2:-2] # cleanup response A\n",
    "chatbot_filtered['response_b'] = chatbot_filtered.response_b.str[2:-2] # cleanup response A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>loser</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30192</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53567</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96401</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198779</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>koala-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292873</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>Construct a rap battle, in the style of Epic R...</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "      <td>(Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>vicuna-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294656694</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>A simple mnemonic for \\u03c0:\\n\\\"How I wish I ...</td>\n",
       "      <td>Sure, let's break it down:\\n\\n1. \\\"How\\\" has 3...</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294692063</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure! Here's an implementation of a naive Baye...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294710549</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>is it unethical to work on building weapons?\",...</td>\n",
       "      <td>Working on weapons technology raises some ethi...</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294899228</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>If a bait contains 0,0025% bromadiolon then ho...</td>\n",
       "      <td>Bromadiolone is a rodenticide which is most of...</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>palm-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294947231</th>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>three kids eat three apples in three days, how...</td>\n",
       "      <td>27 apples</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39716 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_a              model_b  \\\n",
       "id                                                    \n",
       "30192       gpt-4-1106-preview           gpt-4-0613   \n",
       "53567                koala-13b           gpt-4-0613   \n",
       "96401         llama-2-13b-chat  mistral-7b-instruct   \n",
       "198779               koala-13b   gpt-3.5-turbo-0314   \n",
       "292873              vicuna-13b           gpt-4-0314   \n",
       "...                        ...                  ...   \n",
       "4294656694          gpt-4-0613             claude-1   \n",
       "4294692063          claude-2.0     llama-2-13b-chat   \n",
       "4294710549            claude-1           alpaca-13b   \n",
       "4294899228              palm-2       tulu-2-dpo-70b   \n",
       "4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                       prompt  \\\n",
       "id                                                              \n",
       "30192       Is it morally right to try to have a certain p...   \n",
       "53567       What is the difference between marriage licens...   \n",
       "96401       How can I create a test set for a very rare ca...   \n",
       "198779      What is the best way to travel from Tel-Aviv t...   \n",
       "292873      Construct a rap battle, in the style of Epic R...   \n",
       "...                                                       ...   \n",
       "4294656694  A simple mnemonic for \\u03c0:\\n\\\"How I wish I ...   \n",
       "4294692063  In python, implement a naive Bayes with gaussi...   \n",
       "4294710549  is it unethical to work on building weapons?\",...   \n",
       "4294899228  If a bait contains 0,0025% bromadiolon then ho...   \n",
       "4294947231  three kids eat three apples in three days, how...   \n",
       "\n",
       "                                                   response_a  \\\n",
       "id                                                              \n",
       "30192       The question of whether it is morally right to...   \n",
       "53567       A marriage license is a legal document that al...   \n",
       "96401       Creating a test set for a very rare category c...   \n",
       "198779      The best way to travel from Tel Aviv to Jerusa...   \n",
       "292873      [Zeus]\\nYo, it's the king of the gods on the m...   \n",
       "...                                                       ...   \n",
       "4294656694  Sure, let's break it down:\\n\\n1. \\\"How\\\" has 3...   \n",
       "4294692063  Here is an implementation of a naive Bayes cla...   \n",
       "4294710549  Working on weapons technology raises some ethi...   \n",
       "4294899228  Bromadiolone is a rodenticide which is most of...   \n",
       "4294947231                                          27 apples   \n",
       "\n",
       "                                                   response_b  winner_model_a  \\\n",
       "id                                                                              \n",
       "30192       As an AI, I don't have personal beliefs or opi...               1   \n",
       "53567       A marriage license and a marriage certificate ...               0   \n",
       "96401       When building a classifier for a very rare cat...               1   \n",
       "198779      The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "292873      (Verse 1 - Zeus)\\n\\nI'm the king of the gods, ...               0   \n",
       "...                                                       ...             ...   \n",
       "4294656694  Here is how that mnemonic represents the digit...               1   \n",
       "4294692063  Sure! Here's an implementation of a naive Baye...               1   \n",
       "4294710549  It depends on the context. Weapons can be used...               1   \n",
       "4294899228  As an AI language model, I do not promote or c...               0   \n",
       "4294947231  If three kids eat three apples in three days, ...               1   \n",
       "\n",
       "            winner_model_b              winner                loser  \n",
       "id                                                                   \n",
       "30192                    0  gpt-4-1106-preview           gpt-4-0613  \n",
       "53567                    1          gpt-4-0613            koala-13b  \n",
       "96401                    0    llama-2-13b-chat  mistral-7b-instruct  \n",
       "198779                   1  gpt-3.5-turbo-0314            koala-13b  \n",
       "292873                   1          gpt-4-0314           vicuna-13b  \n",
       "...                    ...                 ...                  ...  \n",
       "4294656694               0          gpt-4-0613             claude-1  \n",
       "4294692063               0          claude-2.0     llama-2-13b-chat  \n",
       "4294710549               0            claude-1           alpaca-13b  \n",
       "4294899228               1      tulu-2-dpo-70b               palm-2  \n",
       "4294947231               0  gemini-pro-dev-api   gpt-4-1106-preview  \n",
       "\n",
       "[39716 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_filtered['winner'] = chatbot_filtered.apply(lambda row: row['model_a'] if row['winner_model_a'] else row['model_b'], axis=1)\n",
    "chatbot_filtered['loser'] = chatbot_filtered.apply(lambda row: row['model_a'] if row['winner_model_b'] else row['model_b'], axis=1)\n",
    "chatbot_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>loser</th>\n",
       "      <th>RWKV-4-Raven-14B</th>\n",
       "      <th>alpaca-13b</th>\n",
       "      <th>chatglm-6b</th>\n",
       "      <th>chatglm2-6b</th>\n",
       "      <th>chatglm3-6b</th>\n",
       "      <th>claude-1</th>\n",
       "      <th>claude-2.0</th>\n",
       "      <th>claude-2.1</th>\n",
       "      <th>claude-instant-1</th>\n",
       "      <th>codellama-34b-instruct</th>\n",
       "      <th>...</th>\n",
       "      <th>stripedhyena-nous-7b</th>\n",
       "      <th>tulu-2-dpo-70b</th>\n",
       "      <th>vicuna-13b</th>\n",
       "      <th>vicuna-33b</th>\n",
       "      <th>vicuna-7b</th>\n",
       "      <th>wizardlm-13b</th>\n",
       "      <th>wizardlm-70b</th>\n",
       "      <th>yi-34b-chat</th>\n",
       "      <th>zephyr-7b-alpha</th>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winner</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RWKV-4-Raven-14B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca-13b</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm-6b</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm2-6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatglm3-6b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm-13b</th>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wizardlm-70b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yi-34b-chat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-alpha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zephyr-7b-beta</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "loser             RWKV-4-Raven-14B  alpaca-13b  chatglm-6b  chatglm2-6b  \\\n",
       "winner                                                                    \n",
       "RWKV-4-Raven-14B               0.0        24.0        21.0          0.0   \n",
       "alpaca-13b                    23.0         0.0        38.0          0.0   \n",
       "chatglm-6b                    20.0        26.0         0.0          0.0   \n",
       "chatglm2-6b                    0.0         0.0         0.0          0.0   \n",
       "chatglm3-6b                    0.0         0.0         0.0         14.0   \n",
       "...                            ...         ...         ...          ...   \n",
       "wizardlm-13b                  21.0        17.0         8.0         15.0   \n",
       "wizardlm-70b                   0.0         0.0         0.0         23.0   \n",
       "yi-34b-chat                    0.0         0.0         0.0          2.0   \n",
       "zephyr-7b-alpha                0.0         0.0         0.0          4.0   \n",
       "zephyr-7b-beta                 0.0         0.0         0.0         14.0   \n",
       "\n",
       "loser             chatglm3-6b  claude-1  claude-2.0  claude-2.1  \\\n",
       "winner                                                            \n",
       "RWKV-4-Raven-14B          0.0      14.0         2.0         0.0   \n",
       "alpaca-13b                0.0       8.0         1.0         0.0   \n",
       "chatglm-6b                0.0       5.0         3.0         0.0   \n",
       "chatglm2-6b               4.0       0.0         5.0         0.0   \n",
       "chatglm3-6b               0.0       5.0         5.0         5.0   \n",
       "...                       ...       ...         ...         ...   \n",
       "wizardlm-13b              2.0       9.0        16.0         1.0   \n",
       "wizardlm-70b              3.0      10.0        25.0        20.0   \n",
       "yi-34b-chat              65.0       6.0         6.0        31.0   \n",
       "zephyr-7b-alpha           0.0       1.0         5.0         0.0   \n",
       "zephyr-7b-beta            5.0      14.0         6.0        10.0   \n",
       "\n",
       "loser             claude-instant-1  codellama-34b-instruct  ...  \\\n",
       "winner                                                      ...   \n",
       "RWKV-4-Raven-14B               2.0                     0.0  ...   \n",
       "alpaca-13b                     6.0                     0.0  ...   \n",
       "chatglm-6b                     1.0                     0.0  ...   \n",
       "chatglm2-6b                    1.0                     9.0  ...   \n",
       "chatglm3-6b                    5.0                     4.0  ...   \n",
       "...                            ...                     ...  ...   \n",
       "wizardlm-13b                  19.0                    20.0  ...   \n",
       "wizardlm-70b                  52.0                    22.0  ...   \n",
       "yi-34b-chat                   58.0                     6.0  ...   \n",
       "zephyr-7b-alpha                5.0                    12.0  ...   \n",
       "zephyr-7b-beta                 5.0                    13.0  ...   \n",
       "\n",
       "loser             stripedhyena-nous-7b  tulu-2-dpo-70b  vicuna-13b  \\\n",
       "winner                                                               \n",
       "RWKV-4-Raven-14B                   0.0             0.0        21.0   \n",
       "alpaca-13b                         0.0             0.0        21.0   \n",
       "chatglm-6b                         0.0             0.0        13.0   \n",
       "chatglm2-6b                        0.0             0.0         2.0   \n",
       "chatglm3-6b                        1.0             5.0         1.0   \n",
       "...                                ...             ...         ...   \n",
       "wizardlm-13b                       0.0             2.0        27.0   \n",
       "wizardlm-70b                       3.0             7.0        27.0   \n",
       "yi-34b-chat                        3.0            14.0         7.0   \n",
       "zephyr-7b-alpha                    0.0             0.0         2.0   \n",
       "zephyr-7b-beta                     4.0             4.0        12.0   \n",
       "\n",
       "loser             vicuna-33b  vicuna-7b  wizardlm-13b  wizardlm-70b  \\\n",
       "winner                                                                \n",
       "RWKV-4-Raven-14B         2.0       10.0           6.0           0.0   \n",
       "alpaca-13b               0.0       12.0           9.0           0.0   \n",
       "chatglm-6b               2.0        6.0           1.0           0.0   \n",
       "chatglm2-6b              4.0        0.0           1.0           4.0   \n",
       "chatglm3-6b              3.0        0.0           3.0           2.0   \n",
       "...                      ...        ...           ...           ...   \n",
       "wizardlm-13b            22.0       24.0           0.0          17.0   \n",
       "wizardlm-70b            56.0       17.0          16.0           0.0   \n",
       "yi-34b-chat             56.0        0.0           2.0           8.0   \n",
       "zephyr-7b-alpha          3.0        1.0           1.0           3.0   \n",
       "zephyr-7b-beta          46.0        8.0          36.0           3.0   \n",
       "\n",
       "loser             yi-34b-chat  zephyr-7b-alpha  zephyr-7b-beta  \n",
       "winner                                                          \n",
       "RWKV-4-Raven-14B          0.0              0.0             0.0  \n",
       "alpaca-13b                0.0              0.0             0.0  \n",
       "chatglm-6b                0.0              0.0             0.0  \n",
       "chatglm2-6b               0.0              4.0             8.0  \n",
       "chatglm3-6b              12.0              0.0             2.0  \n",
       "...                       ...              ...             ...  \n",
       "wizardlm-13b              1.0              7.0            59.0  \n",
       "wizardlm-70b             12.0              3.0             3.0  \n",
       "yi-34b-chat               0.0              0.0             8.0  \n",
       "zephyr-7b-alpha           0.0              0.0             9.0  \n",
       "zephyr-7b-beta            6.0              9.0             0.0  \n",
       "\n",
       "[64 rows x 64 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wins_df = chatbot_filtered[['winner', 'loser']].copy()\n",
    "wins_df['wins'] = 1\n",
    "wins_df = wins_df.groupby(by=['winner', 'loser'], sort=True, as_index=False).count()\n",
    "wins_df = wins_df.pivot(index='winner', columns='loser', values='wins').replace({np.NaN: 0})\n",
    "wins_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koala-13b</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>[Zeus]\\nYo, it's the king of the gods on the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79427</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79428</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>Sure! Here's an implementation of a naive Baye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79429</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>It depends on the context. Weapons can be used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79430</th>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>As an AI language model, I do not promote or c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79431</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>If three kids eat three apples in three days, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79432 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                                           response\n",
       "0      gpt-4-1106-preview  The question of whether it is morally right to...\n",
       "1               koala-13b  A marriage license is a legal document that al...\n",
       "2        llama-2-13b-chat  Creating a test set for a very rare category c...\n",
       "3               koala-13b  The best way to travel from Tel Aviv to Jerusa...\n",
       "4              vicuna-13b  [Zeus]\\nYo, it's the king of the gods on the m...\n",
       "...                   ...                                                ...\n",
       "79427            claude-1  Here is how that mnemonic represents the digit...\n",
       "79428    llama-2-13b-chat  Sure! Here's an implementation of a naive Baye...\n",
       "79429          alpaca-13b  It depends on the context. Weapons can be used...\n",
       "79430      tulu-2-dpo-70b  As an AI language model, I do not promote or c...\n",
       "79431  gpt-4-1106-preview  If three kids eat three apples in three days, ...\n",
       "\n",
       "[79432 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_df = chatbot_filtered.melt(id_vars=['model_a', 'model_b'], value_vars=['response_a', 'response_b'], value_name='response')\n",
    "response_df['model'] = response_df.apply(lambda row: row['model_a'] if row['variable'] == 'response_a' else row['model_b'], axis=1)\n",
    "response_df = response_df[['model', 'response']]\n",
    "response_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>958.310388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>385.409369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>1074.943099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>1185.141007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  response_length  long_response\n",
       "0   RWKV-4-Raven-14B       958.310388              0\n",
       "1         alpaca-13b       385.409369              0\n",
       "2         chatglm-6b      1074.943099              0\n",
       "3        chatglm2-6b      1159.600509              0\n",
       "4        chatglm3-6b      1185.141007              0\n",
       "..               ...              ...            ...\n",
       "59      wizardlm-13b      1318.800000              0\n",
       "60      wizardlm-70b      1543.451872              1\n",
       "61       yi-34b-chat      2074.278520              1\n",
       "62   zephyr-7b-alpha      1413.000000              1\n",
       "63    zephyr-7b-beta      1553.310345              1\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_df = response_df.copy()\n",
    "length_df['response_length'] = length_df.response.str.len()\n",
    "length_df = length_df[['model', 'response_length']].groupby('model', as_index=False).mean()\n",
    "length_df['long_response'] = (length_df.response_length >= length_df.response_length.median()).astype(int)\n",
    "length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>falcon-180b-chat</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>2923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>3969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>4306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>4866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>5360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  comparisons  often_compared\n",
       "34  mistral-7b-instruct-v0.2           72               0\n",
       "48           qwen1.5-4b-chat          124               0\n",
       "50           qwen1.5-7b-chat          140               0\n",
       "42         openchat-3.5-0106          159               0\n",
       "13          falcon-180b-chat          203               0\n",
       "..                       ...          ...             ...\n",
       "22                gpt-4-0314         2923               1\n",
       "7                 claude-2.1         3969               1\n",
       "23                gpt-4-0613         4306               1\n",
       "19        gpt-3.5-turbo-0613         4866               1\n",
       "24        gpt-4-1106-preview         5360               1\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = chatbot_filtered[['model_a', 'model_b']].copy()\n",
    "comparison_df = pd.DataFrame({'model': pd.concat([comparison_df['model_a'], comparison_df['model_b']]).astype(str)})\n",
    "comparison_df['comparisons'] = 1\n",
    "comparison_df = comparison_df.groupby('model', as_index=False).count().sort_values('comparisons')\n",
    "comparison_df['often_compared'] = (comparison_df.comparisons >= comparison_df.comparisons.median()).astype(int)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>openchat-3.5-0106</td>\n",
       "      <td>74</td>\n",
       "      <td>159</td>\n",
       "      <td>0.465409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>553</td>\n",
       "      <td>1174</td>\n",
       "      <td>0.471039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>127</td>\n",
       "      <td>267</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mpt-7b-chat</td>\n",
       "      <td>307</td>\n",
       "      <td>643</td>\n",
       "      <td>0.477449</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>465</td>\n",
       "      <td>973</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama2-70b-steerlm-chat</td>\n",
       "      <td>242</td>\n",
       "      <td>458</td>\n",
       "      <td>0.528384</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qwen1.5-7b-chat</td>\n",
       "      <td>74</td>\n",
       "      <td>140</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt4all-13b-snoozy</td>\n",
       "      <td>147</td>\n",
       "      <td>277</td>\n",
       "      <td>0.530686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>283</td>\n",
       "      <td>519</td>\n",
       "      <td>0.545279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>41</td>\n",
       "      <td>72</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  first_comparisons  comparisons  first_percent  \\\n",
       "3          openchat-3.5-0106                 74          159       0.465409   \n",
       "45           llama-2-7b-chat                553         1174       0.471039   \n",
       "7            zephyr-7b-alpha                127          267       0.475655   \n",
       "21               mpt-7b-chat                307          643       0.477449   \n",
       "32               yi-34b-chat                465          973       0.477903   \n",
       "..                       ...                ...          ...            ...   \n",
       "14   llama2-70b-steerlm-chat                242          458       0.528384   \n",
       "2            qwen1.5-7b-chat                 74          140       0.528571   \n",
       "8         gpt4all-13b-snoozy                147          277       0.530686   \n",
       "17     deepseek-llm-67b-chat                283          519       0.545279   \n",
       "0   mistral-7b-instruct-v0.2                 41           72       0.569444   \n",
       "\n",
       "    often_first  \n",
       "3             0  \n",
       "45            0  \n",
       "7             0  \n",
       "21            0  \n",
       "32            0  \n",
       "..          ...  \n",
       "14            1  \n",
       "2             1  \n",
       "8             1  \n",
       "17            1  \n",
       "0             1  \n",
       "\n",
       "[64 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstModel_df = chatbot_filtered[['model_a']].copy()\n",
    "firstModel_df['first_comparisons'] = 1\n",
    "firstModel_df = firstModel_df.groupby('model_a', as_index=False).count().sort_values('first_comparisons').rename(columns={'model_a': 'model'})\n",
    "firstModel_df = firstModel_df.merge(comparison_df[['model', 'comparisons']], on='model')\n",
    "firstModel_df['first_percent'] = firstModel_df.first_comparisons / firstModel_df.comparisons\n",
    "firstModel_df['often_first'] = (firstModel_df.first_percent >= firstModel_df.first_percent.median()).astype(int)\n",
    "firstModel_df.sort_values('first_percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_619275/2825499135.py:4: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  formatted_df['markdown'] = formatted_df.response.str.contains(r'\\s(__|\\*\\*|```)(?!\\s)(.(?!\\1))+(?!\\s(?=\\1))', regex=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>formatted</th>\n",
       "      <th>often_formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fastchat-t5-3b</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>llama-13b</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>qwen1.5-4b-chat</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mistral-7b-instruct-v0.2</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude-1</td>\n",
       "      <td>2382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>2723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>3043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>3061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>4564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  formatted  often_formatted\n",
       "14            fastchat-t5-3b          5                0\n",
       "0           RWKV-4-Raven-14B          7                0\n",
       "28                 llama-13b         12                0\n",
       "48           qwen1.5-4b-chat         52                0\n",
       "34  mistral-7b-instruct-v0.2         53                0\n",
       "..                       ...        ...              ...\n",
       "5                   claude-1       2382                1\n",
       "23                gpt-4-0613       2723                1\n",
       "19        gpt-3.5-turbo-0613       3043                1\n",
       "7                 claude-2.1       3061                1\n",
       "24        gpt-4-1106-preview       4564                1\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df = response_df.copy()\n",
    "# detect formatting with (i) double newlines and (ii) double underscores or asterisks or ``` (markdown)\n",
    "formatted_df['double_newlines'] = formatted_df.response.str.contains('\\\\n\\\\n', regex=False)\n",
    "formatted_df['markdown'] = formatted_df.response.str.contains(r'\\s(__|\\*\\*|```)(?!\\s)(.(?!\\1))+(?!\\s(?=\\1))', regex=True)\n",
    "formatted_df['formatted'] = (formatted_df.double_newlines | formatted_df.markdown).astype(int)\n",
    "formatted_df = formatted_df[['model', 'formatted']].groupby('model', as_index=False).sum()\n",
    "formatted_df['often_formatted'] = (formatted_df.formatted >= formatted_df.formatted.median()).astype(int)\n",
    "formatted_df.sort_values('formatted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RWKV-4-Raven-14B',\n",
       " 'alpaca-13b',\n",
       " 'chatglm-6b',\n",
       " 'chatglm2-6b',\n",
       " 'chatglm3-6b',\n",
       " 'claude-1',\n",
       " 'claude-2.0',\n",
       " 'claude-2.1',\n",
       " 'claude-instant-1',\n",
       " 'codellama-34b-instruct',\n",
       " 'deepseek-llm-67b-chat',\n",
       " 'dolly-v2-12b',\n",
       " 'dolphin-2.2.1-mistral-7b',\n",
       " 'falcon-180b-chat',\n",
       " 'fastchat-t5-3b',\n",
       " 'gemini-pro',\n",
       " 'gemini-pro-dev-api',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-3.5-turbo-0314',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-4-0314',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-4-1106-preview',\n",
       " 'gpt4all-13b-snoozy',\n",
       " 'guanaco-33b',\n",
       " 'koala-13b',\n",
       " 'llama-13b',\n",
       " 'llama-2-13b-chat',\n",
       " 'llama-2-70b-chat',\n",
       " 'llama-2-7b-chat',\n",
       " 'llama2-70b-steerlm-chat',\n",
       " 'mistral-7b-instruct',\n",
       " 'mistral-7b-instruct-v0.2',\n",
       " 'mistral-medium',\n",
       " 'mixtral-8x7b-instruct-v0.1',\n",
       " 'mpt-30b-chat',\n",
       " 'mpt-7b-chat',\n",
       " 'nous-hermes-2-mixtral-8x7b-dpo',\n",
       " 'oasst-pythia-12b',\n",
       " 'openchat-3.5',\n",
       " 'openchat-3.5-0106',\n",
       " 'openhermes-2.5-mistral-7b',\n",
       " 'palm-2',\n",
       " 'pplx-70b-online',\n",
       " 'pplx-7b-online',\n",
       " 'qwen-14b-chat',\n",
       " 'qwen1.5-4b-chat',\n",
       " 'qwen1.5-72b-chat',\n",
       " 'qwen1.5-7b-chat',\n",
       " 'solar-10.7b-instruct-v1.0',\n",
       " 'stablelm-tuned-alpha-7b',\n",
       " 'starling-lm-7b-alpha',\n",
       " 'stripedhyena-nous-7b',\n",
       " 'tulu-2-dpo-70b',\n",
       " 'vicuna-13b',\n",
       " 'vicuna-33b',\n",
       " 'vicuna-7b',\n",
       " 'wizardlm-13b',\n",
       " 'wizardlm-70b',\n",
       " 'yi-34b-chat',\n",
       " 'zephyr-7b-alpha',\n",
       " 'zephyr-7b-beta']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_df.model.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  open_source\n",
       "0   RWKV-4-Raven-14B            1\n",
       "1         alpaca-13b            0\n",
       "2         chatglm-6b            1\n",
       "3        chatglm2-6b            1\n",
       "4        chatglm3-6b            1\n",
       "..               ...          ...\n",
       "59      wizardlm-13b            1\n",
       "60      wizardlm-70b            1\n",
       "61       yi-34b-chat            1\n",
       "62   zephyr-7b-alpha            1\n",
       "63    zephyr-7b-beta            1\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenSource operationalized as available on HuggingFace\n",
    "opensource_df = pd.DataFrame([{'model': 'RWKV-4-Raven-14B', 'open_source': True},\n",
    "                              {'model': 'alpaca-13b', 'open_source': False},\n",
    "                              {'model': 'chatglm-6b', 'open_source': True},\n",
    "                              {'model': 'chatglm2-6b', 'open_source': True},\n",
    "                              {'model': 'chatglm3-6b', 'open_source': True},\n",
    "                              {'model': 'claude-1', 'open_source': False},\n",
    "                              {'model': 'claude-2.0', 'open_source': False},\n",
    "                              {'model': 'claude-2.1', 'open_source': False},\n",
    "                              {'model': 'claude-instant-1', 'open_source': False},\n",
    "                              {'model': 'codellama-34b-instruct', 'open_source': True},\n",
    "                              {'model': 'deepseek-llm-67b-chat', 'open_source': True},\n",
    "                              {'model': 'dolly-v2-12b', 'open_source': True},\n",
    "                              {'model': 'dolphin-2.2.1-mistral-7b', 'open_source': True},\n",
    "                              {'model': 'falcon-180b-chat', 'open_source': True},\n",
    "                              {'model': 'fastchat-t5-3b', 'open_source': True},\n",
    "                              {'model': 'gemini-pro', 'open_source': False},\n",
    "                              {'model': 'gemini-pro-dev-api', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-0125', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-0314', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-0613', 'open_source': False},\n",
    "                              {'model': 'gpt-3.5-turbo-1106', 'open_source': False},\n",
    "                              {'model': 'gpt-4-0125-preview', 'open_source': False},\n",
    "                              {'model': 'gpt-4-0314', 'open_source': False},\n",
    "                              {'model': 'gpt-4-0613', 'open_source': False},\n",
    "                              {'model': 'gpt-4-1106-preview', 'open_source': False},\n",
    "                              {'model': 'gpt4all-13b-snoozy', 'open_source': True},\n",
    "                              {'model': 'guanaco-33b', 'open_source': False},\n",
    "                              {'model': 'koala-13b', 'open_source': False},\n",
    "                              {'model': 'llama-13b', 'open_source': True},\n",
    "                              {'model': 'llama-2-13b-chat', 'open_source': True},\n",
    "                              {'model': 'llama-2-70b-chat', 'open_source': True},\n",
    "                              {'model': 'llama-2-7b-chat', 'open_source': True},\n",
    "                              {'model': 'llama2-70b-steerlm-chat', 'open_source': True},\n",
    "                              {'model': 'mistral-7b-instruct', 'open_source': True},\n",
    "                              {'model': 'mistral-7b-instruct-v0.2', 'open_source': True},\n",
    "                              {'model': 'mistral-medium', 'open_source': False},\n",
    "                              {'model': 'mixtral-8x7b-instruct-v0.1', 'open_source': True},\n",
    "                              {'model': 'mpt-30b-chat', 'open_source': True},\n",
    "                              {'model': 'mpt-7b-chat', 'open_source': True},\n",
    "                              {'model': 'nous-hermes-2-mixtral-8x7b-dpo', 'open_source': True},\n",
    "                              {'model': 'oasst-pythia-12b', 'open_source': True},\n",
    "                              {'model': 'openchat-3.5', 'open_source': True},\n",
    "                              {'model': 'openchat-3.5-0106', 'open_source': True},\n",
    "                              {'model': 'openhermes-2.5-mistral-7b', 'open_source': True},\n",
    "                              {'model': 'palm-2', 'open_source': False},\n",
    "                              {'model': 'pplx-70b-online', 'open_source': False},\n",
    "                              {'model': 'pplx-7b-online', 'open_source': False},\n",
    "                              {'model': 'qwen-14b-chat', 'open_source': True},\n",
    "                              {'model': 'qwen1.5-4b-chat', 'open_source': True},\n",
    "                              {'model': 'qwen1.5-72b-chat', 'open_source': True},\n",
    "                              {'model': 'qwen1.5-7b-chat', 'open_source': True},\n",
    "                              {'model': 'solar-10.7b-instruct-v1.0', 'open_source': True},\n",
    "                              {'model': 'stablelm-tuned-alpha-7b', 'open_source': True},\n",
    "                              {'model': 'starling-lm-7b-alpha', 'open_source': True},\n",
    "                              {'model': 'stripedhyena-nous-7b', 'open_source': True},\n",
    "                              {'model': 'tulu-2-dpo-70b', 'open_source': True},\n",
    "                              {'model': 'vicuna-13b', 'open_source': True},\n",
    "                              {'model': 'vicuna-33b', 'open_source': True},\n",
    "                              {'model': 'vicuna-7b', 'open_source': True},\n",
    "                              {'model': 'wizardlm-13b', 'open_source': True},\n",
    "                              {'model': 'wizardlm-70b', 'open_source': True},\n",
    "                              {'model': 'yi-34b-chat', 'open_source': True},\n",
    "                              {'model': 'zephyr-7b-alpha', 'open_source': True},\n",
    "                              {'model': 'zephyr-7b-beta', 'open_source': True}])\n",
    "opensource_df['open_source'] = opensource_df.open.astype(int)\n",
    "opensource_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RWKV-4-Raven-14B</td>\n",
       "      <td>958.310388</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0.519399</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>385.409369</td>\n",
       "      <td>0</td>\n",
       "      <td>982</td>\n",
       "      <td>1</td>\n",
       "      <td>487</td>\n",
       "      <td>0.495927</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>1074.943099</td>\n",
       "      <td>0</td>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "      <td>0.496368</td>\n",
       "      <td>0</td>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0.498728</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chatglm3-6b</td>\n",
       "      <td>1185.141007</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0.509353</td>\n",
       "      <td>1</td>\n",
       "      <td>446</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0</td>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>1</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "      <td>813</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               model  response_length  long_response  comparisons  \\\n",
       "0   RWKV-4-Raven-14B       958.310388              0          799   \n",
       "1         alpaca-13b       385.409369              0          982   \n",
       "2         chatglm-6b      1074.943099              0          826   \n",
       "3        chatglm2-6b      1159.600509              0          393   \n",
       "4        chatglm3-6b      1185.141007              0          695   \n",
       "..               ...              ...            ...          ...   \n",
       "59      wizardlm-13b      1318.800000              0         1055   \n",
       "60      wizardlm-70b      1543.451872              1         1122   \n",
       "61       yi-34b-chat      2074.278520              1          973   \n",
       "62   zephyr-7b-alpha      1413.000000              1          267   \n",
       "63    zephyr-7b-beta      1553.310345              1         1624   \n",
       "\n",
       "    often_compared  first_comparisons  first_percent  often_first  formatted  \\\n",
       "0                0                415       0.519399            1          7   \n",
       "1                1                487       0.495927            0         65   \n",
       "2                0                410       0.496368            0        524   \n",
       "3                0                196       0.498728            0        266   \n",
       "4                0                354       0.509353            1        446   \n",
       "..             ...                ...            ...          ...        ...   \n",
       "59               1                517       0.490047            0        735   \n",
       "60               1                539       0.480392            0        881   \n",
       "61               1                465       0.477903            0        812   \n",
       "62               0                127       0.475655            0        161   \n",
       "63               1                813       0.500616            1       1078   \n",
       "\n",
       "    often_formatted  open_source  \n",
       "0                 0            1  \n",
       "1                 0            0  \n",
       "2                 0            1  \n",
       "3                 0            1  \n",
       "4                 0            1  \n",
       "..              ...          ...  \n",
       "59                1            1  \n",
       "60                1            1  \n",
       "61                1            1  \n",
       "62                0            1  \n",
       "63                1            1  \n",
       "\n",
       "[64 rows x 11 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_df = length_df.merge(comparison_df, on='model').merge(firstModel_df.drop(columns='comparisons'), on='model')\n",
    "groups_df = groups_df.merge(formatted_df, on='model').merge(opensource_df, on='model')\n",
    "groups_df.to_csv('../fairpair/data/chatbot_arena/models.csv', index=False)\n",
    "groups_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arena-Hard Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>77.96</td>\n",
       "      <td>2700.263158</td>\n",
       "      <td>1</td>\n",
       "      <td>798</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>0.483709</td>\n",
       "      <td>0</td>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1414.471433</td>\n",
       "      <td>0</td>\n",
       "      <td>2923</td>\n",
       "      <td>1</td>\n",
       "      <td>1478</td>\n",
       "      <td>0.505645</td>\n",
       "      <td>1</td>\n",
       "      <td>1864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>37.90</td>\n",
       "      <td>1300.464933</td>\n",
       "      <td>0</td>\n",
       "      <td>4306</td>\n",
       "      <td>1</td>\n",
       "      <td>2167</td>\n",
       "      <td>0.503251</td>\n",
       "      <td>1</td>\n",
       "      <td>2723</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>36.12</td>\n",
       "      <td>1760.043243</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>31.90</td>\n",
       "      <td>1863.079785</td>\n",
       "      <td>1</td>\n",
       "      <td>2231</td>\n",
       "      <td>1</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>1</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>24.82</td>\n",
       "      <td>1407.265105</td>\n",
       "      <td>0</td>\n",
       "      <td>4866</td>\n",
       "      <td>1</td>\n",
       "      <td>2448</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>1</td>\n",
       "      <td>3043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>23.99</td>\n",
       "      <td>1224.380241</td>\n",
       "      <td>0</td>\n",
       "      <td>1741</td>\n",
       "      <td>0</td>\n",
       "      <td>908</td>\n",
       "      <td>0.521539</td>\n",
       "      <td>1</td>\n",
       "      <td>1377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>23.40</td>\n",
       "      <td>1622.423525</td>\n",
       "      <td>1</td>\n",
       "      <td>2406</td>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.487116</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>23.34</td>\n",
       "      <td>1249.145833</td>\n",
       "      <td>0</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>0.496528</td>\n",
       "      <td>0</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>23.15</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>22.77</td>\n",
       "      <td>1247.284203</td>\n",
       "      <td>0</td>\n",
       "      <td>3969</td>\n",
       "      <td>1</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>18.87</td>\n",
       "      <td>965.039707</td>\n",
       "      <td>0</td>\n",
       "      <td>2317</td>\n",
       "      <td>1</td>\n",
       "      <td>1163</td>\n",
       "      <td>0.501942</td>\n",
       "      <td>1</td>\n",
       "      <td>1070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>18.05</td>\n",
       "      <td>820.575413</td>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>0</td>\n",
       "      <td>484</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>17.80</td>\n",
       "      <td>1382.902778</td>\n",
       "      <td>0</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0.499008</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>14.99</td>\n",
       "      <td>1674.544676</td>\n",
       "      <td>1</td>\n",
       "      <td>817</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>0.483476</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>starling-lm-7b-alpha</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1651.135065</td>\n",
       "      <td>1</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>0.501299</td>\n",
       "      <td>0</td>\n",
       "      <td>665</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>12.57</td>\n",
       "      <td>1203.310565</td>\n",
       "      <td>0</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>llama-2-70b-chat</td>\n",
       "      <td>11.55</td>\n",
       "      <td>1873.066091</td>\n",
       "      <td>1</td>\n",
       "      <td>2315</td>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>0.478186</td>\n",
       "      <td>0</td>\n",
       "      <td>2026</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vicuna-33b</td>\n",
       "      <td>8.63</td>\n",
       "      <td>1516.407604</td>\n",
       "      <td>1</td>\n",
       "      <td>2446</td>\n",
       "      <td>1</td>\n",
       "      <td>1248</td>\n",
       "      <td>0.510221</td>\n",
       "      <td>1</td>\n",
       "      <td>1827</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  score  response_length  long_response  \\\n",
       "0           gpt-4-0125-preview  77.96      2700.263158              1   \n",
       "1                   gpt-4-0314  50.00      1414.471433              0   \n",
       "2                   gpt-4-0613  37.90      1300.464933              0   \n",
       "3             qwen1.5-72b-chat  36.12      1760.043243              1   \n",
       "4               mistral-medium  31.90      1863.079785              1   \n",
       "5           gpt-3.5-turbo-0613  24.82      1407.265105              0   \n",
       "6                   claude-2.0  23.99      1224.380241              0   \n",
       "7   mixtral-8x7b-instruct-v0.1  23.40      1622.423525              1   \n",
       "8           gpt-3.5-turbo-0125  23.34      1249.145833              0   \n",
       "9                  yi-34b-chat  23.15      2074.278520              1   \n",
       "10                  claude-2.1  22.77      1247.284203              0   \n",
       "11          gpt-3.5-turbo-1106  18.87       965.039707              0   \n",
       "12          gpt-3.5-turbo-0314  18.05       820.575413              0   \n",
       "13                  gemini-pro  17.80      1382.902778              0   \n",
       "14              tulu-2-dpo-70b  14.99      1674.544676              1   \n",
       "15        starling-lm-7b-alpha  12.80      1651.135065              1   \n",
       "16         mistral-7b-instruct  12.57      1203.310565              0   \n",
       "17            llama-2-70b-chat  11.55      1873.066091              1   \n",
       "18                  vicuna-33b   8.63      1516.407604              1   \n",
       "\n",
       "    comparisons  often_compared  first_comparisons  first_percent  \\\n",
       "0           798               0                386       0.483709   \n",
       "1          2923               1               1478       0.505645   \n",
       "2          4306               1               2167       0.503251   \n",
       "3           370               0                190       0.513514   \n",
       "4          2231               1               1145       0.513223   \n",
       "5          4866               1               2448       0.503083   \n",
       "6          1741               0                908       0.521539   \n",
       "7          2406               1               1172       0.487116   \n",
       "8           576               0                286       0.496528   \n",
       "9           973               0                465       0.477903   \n",
       "10         3969               1               2058       0.518519   \n",
       "11         2317               1               1163       0.501942   \n",
       "12          968               0                484       0.500000   \n",
       "13         1008               0                503       0.499008   \n",
       "14          817               0                395       0.483476   \n",
       "15          770               0                386       0.501299   \n",
       "16         1098               0                534       0.486339   \n",
       "17         2315               1               1107       0.478186   \n",
       "18         2446               1               1248       0.510221   \n",
       "\n",
       "    often_first  formatted  often_formatted  open_source  \n",
       "0             0        656                0            0  \n",
       "1             1       1864                1            0  \n",
       "2             1       2723                1            0  \n",
       "3             1        274                0            1  \n",
       "4             1       1807                1            0  \n",
       "5             1       3043                1            0  \n",
       "6             1       1377                1            0  \n",
       "7             0       1930                1            1  \n",
       "8             0        327                0            0  \n",
       "9             0        812                0            1  \n",
       "10            1       3061                1            0  \n",
       "11            1       1070                0            0  \n",
       "12            0        515                0            0  \n",
       "13            0        702                0            0  \n",
       "14            0        669                0            1  \n",
       "15            0        665                0            1  \n",
       "16            0        643                0            1  \n",
       "17            0       2026                1            1  \n",
       "18            1       1827                1            1  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.read_csv('../arena-hard/leaderboard/arena_hard_leaderboard_20240924.csv')\n",
    "#scores_df = pd.read_csv('../arena-hard/leaderboard/arena_hard_leaderboard_20240731.csv')\n",
    "\n",
    "_df = scores_df[['model', 'score']].merge(groups_df, on='model')\n",
    "\n",
    "# recalculate top/bottom 50%\n",
    "_df['long_response'] = (_df.response_length > _df.response_length.median()).astype(int)\n",
    "_df['often_compared'] = (_df.comparisons > _df.comparisons.median()).astype(int)\n",
    "_df['often_first'] = (_df.first_percent > _df.first_percent.median()).astype(int)\n",
    "_df['often_formatted'] = (_df.formatted > _df.formatted.median()).astype(int)\n",
    "arena_hard_combined = _df\n",
    "\n",
    "arena_hard_combined.sort_values('score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93c9b4bb32f4422f954c7af9ea2bdfcd</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>llama-3.1-8b-instruct</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88737</th>\n",
       "      <td>de6e5b0884554e3a80d7c29e72d9306a</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88738</th>\n",
       "      <td>f9111d1c39744147976e90c820838582</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88739</th>\n",
       "      <td>f9111d1c39744147976e90c820838582</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88740</th>\n",
       "      <td>7956046cc15646909bd07c31d0ea0371</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88741</th>\n",
       "      <td>7956046cc15646909bd07c31d0ea0371</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88742 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question_id     model_a                model_b  \\\n",
       "0      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "1      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "2      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "3      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "4      93c9b4bb32f4422f954c7af9ea2bdfcd  gpt-4-0314  llama-3.1-8b-instruct   \n",
       "...                                 ...         ...                    ...   \n",
       "88737  de6e5b0884554e3a80d7c29e72d9306a  gpt-4-0314             claude-2.0   \n",
       "88738  f9111d1c39744147976e90c820838582  gpt-4-0314             claude-2.0   \n",
       "88739  f9111d1c39744147976e90c820838582  gpt-4-0314             claude-2.0   \n",
       "88740  7956046cc15646909bd07c31d0ea0371  gpt-4-0314             claude-2.0   \n",
       "88741  7956046cc15646909bd07c31d0ea0371  gpt-4-0314             claude-2.0   \n",
       "\n",
       "        winner  \n",
       "0      model_a  \n",
       "1      model_a  \n",
       "2      model_a  \n",
       "3      model_a  \n",
       "4      model_a  \n",
       "...        ...  \n",
       "88737  model_a  \n",
       "88738  model_a  \n",
       "88739  model_b  \n",
       "88740  model_a  \n",
       "88741      tie  \n",
       "\n",
       "[88742 rows x 4 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_hard_df = pd.read_json('../arena-hard/data/arena_hard_battles.jsonl', lines=True)\n",
    "comparison_hard_df # always compared to gpt-4-0314 as a baseline, so more of a stargraph than truly pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlpacaEval 2.0 Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>21.855773</td>\n",
       "      <td>1863.079785</td>\n",
       "      <td>1</td>\n",
       "      <td>2231</td>\n",
       "      <td>1</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>1</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>18.177645</td>\n",
       "      <td>1382.902778</td>\n",
       "      <td>1</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0.499008</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>15.982854</td>\n",
       "      <td>1674.544676</td>\n",
       "      <td>1</td>\n",
       "      <td>817</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>0.483476</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>15.733507</td>\n",
       "      <td>1247.284203</td>\n",
       "      <td>0</td>\n",
       "      <td>3969</td>\n",
       "      <td>1</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wizardlm-70b</td>\n",
       "      <td>14.383896</td>\n",
       "      <td>1543.451872</td>\n",
       "      <td>1</td>\n",
       "      <td>1122</td>\n",
       "      <td>1</td>\n",
       "      <td>539</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0</td>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>14.095799</td>\n",
       "      <td>1407.265105</td>\n",
       "      <td>1</td>\n",
       "      <td>4866</td>\n",
       "      <td>1</td>\n",
       "      <td>2448</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>1</td>\n",
       "      <td>3043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>12.093422</td>\n",
       "      <td>1336.406551</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0.545279</td>\n",
       "      <td>1</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zephyr-7b-beta</td>\n",
       "      <td>10.992886</td>\n",
       "      <td>1553.310345</td>\n",
       "      <td>1</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "      <td>813</td>\n",
       "      <td>0.500616</td>\n",
       "      <td>1</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>9.177965</td>\n",
       "      <td>965.039707</td>\n",
       "      <td>0</td>\n",
       "      <td>2317</td>\n",
       "      <td>1</td>\n",
       "      <td>1163</td>\n",
       "      <td>0.501942</td>\n",
       "      <td>1</td>\n",
       "      <td>1070</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dolphin-2.2.1-mistral-7b</td>\n",
       "      <td>9.039800</td>\n",
       "      <td>1395.445833</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zephyr-7b-alpha</td>\n",
       "      <td>8.352664</td>\n",
       "      <td>1413.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0.475655</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>wizardlm-13b</td>\n",
       "      <td>5.878153</td>\n",
       "      <td>1318.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>1055</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>0.490047</td>\n",
       "      <td>0</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>5.831103</td>\n",
       "      <td>1128.109237</td>\n",
       "      <td>0</td>\n",
       "      <td>2371</td>\n",
       "      <td>1</td>\n",
       "      <td>1159</td>\n",
       "      <td>0.488823</td>\n",
       "      <td>0</td>\n",
       "      <td>1520</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>guanaco-33b</td>\n",
       "      <td>5.002494</td>\n",
       "      <td>1180.433260</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>0.507659</td>\n",
       "      <td>1</td>\n",
       "      <td>372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vicuna-7b</td>\n",
       "      <td>4.162611</td>\n",
       "      <td>1136.807586</td>\n",
       "      <td>0</td>\n",
       "      <td>1081</td>\n",
       "      <td>1</td>\n",
       "      <td>522</td>\n",
       "      <td>0.482886</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chatglm2-6b</td>\n",
       "      <td>2.762185</td>\n",
       "      <td>1159.600509</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>0.498728</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model   win_rate  response_length  long_response  \\\n",
       "0             mistral-medium  21.855773      1863.079785              1   \n",
       "1                 gemini-pro  18.177645      1382.902778              1   \n",
       "2             tulu-2-dpo-70b  15.982854      1674.544676              1   \n",
       "3                 claude-2.1  15.733507      1247.284203              0   \n",
       "4               wizardlm-70b  14.383896      1543.451872              1   \n",
       "5         gpt-3.5-turbo-0613  14.095799      1407.265105              1   \n",
       "6      deepseek-llm-67b-chat  12.093422      1336.406551              0   \n",
       "7             zephyr-7b-beta  10.992886      1553.310345              1   \n",
       "8         gpt-3.5-turbo-1106   9.177965       965.039707              0   \n",
       "9   dolphin-2.2.1-mistral-7b   9.039800      1395.445833              1   \n",
       "10           zephyr-7b-alpha   8.352664      1413.000000              1   \n",
       "11              wizardlm-13b   5.878153      1318.800000              0   \n",
       "12                vicuna-13b   5.831103      1128.109237              0   \n",
       "13               guanaco-33b   5.002494      1180.433260              0   \n",
       "14                 vicuna-7b   4.162611      1136.807586              0   \n",
       "15               chatglm2-6b   2.762185      1159.600509              0   \n",
       "\n",
       "    comparisons  often_compared  first_comparisons  first_percent  \\\n",
       "0          2231               1               1145       0.513223   \n",
       "1          1008               0                503       0.499008   \n",
       "2           817               0                395       0.483476   \n",
       "3          3969               1               2058       0.518519   \n",
       "4          1122               1                539       0.480392   \n",
       "5          4866               1               2448       0.503083   \n",
       "6           519               0                283       0.545279   \n",
       "7          1624               1                813       0.500616   \n",
       "8          2317               1               1163       0.501942   \n",
       "9           240               0                125       0.520833   \n",
       "10          267               0                127       0.475655   \n",
       "11         1055               0                517       0.490047   \n",
       "12         2371               1               1159       0.488823   \n",
       "13          457               0                232       0.507659   \n",
       "14         1081               1                522       0.482886   \n",
       "15          393               0                196       0.498728   \n",
       "\n",
       "    often_first  formatted  often_formatted  open_source  \n",
       "0             1       1807                1            0  \n",
       "1             0        702                0            0  \n",
       "2             0        669                0            1  \n",
       "3             1       3061                1            0  \n",
       "4             0        881                1            1  \n",
       "5             1       3043                1            0  \n",
       "6             1        369                0            1  \n",
       "7             1       1078                1            1  \n",
       "8             1       1070                1            0  \n",
       "9             1        172                0            1  \n",
       "10            0        161                0            1  \n",
       "11            0        735                1            1  \n",
       "12            0       1520                1            1  \n",
       "13            1        372                0            0  \n",
       "14            0        670                0            1  \n",
       "15            0        266                0            1  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresAlpaca_df = pd.read_csv('../fairpair/data/chatbot_arena/weighted_alpaca_eval_gpt4_turbo_leaderboard.csv').rename(columns={'Unnamed: 0': 'model'})\n",
    "_df = scoresAlpaca_df[['model', 'win_rate']].merge(groups_df, on='model')\n",
    "\n",
    "# recalculate top/bottom 50%\n",
    "_df['long_response'] = (_df.response_length > _df.response_length.median()).astype(int)\n",
    "_df['often_compared'] = (_df.comparisons > _df.comparisons.median()).astype(int)\n",
    "_df['often_first'] = (_df.first_percent > _df.first_percent.median()).astype(int)\n",
    "_df['often_formatted'] = (_df.formatted > _df.formatted.median()).astype(int)\n",
    "alpaca_combined = _df\n",
    "\n",
    "alpaca_combined.sort_values('win_rate', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HELM Lite Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "helm_df = pd.DataFrame([\n",
    "    {'model': 'claude-2.0', 'win_rate': 0.55},\n",
    "    {'model': 'claude-2.1', 'win_rate': 0.494},\n",
    "    {'model': 'claude-instant-1', 'win_rate': 0.455},\n",
    "    {'model': 'deepseek-llm-67b-chat', 'win_rate': 0.546},\n",
    "    {'model': 'gemini-pro', 'win_rate': 0.474},\n",
    "    {'model': 'gpt-3.5-turbo-0613', 'win_rate': 0.408},\n",
    "    {'model': 'gpt-4-0613', 'win_rate': 0.915},\n",
    "    {'model': 'gpt-4-1106-preview', 'win_rate': 0.756},\n",
    "    {'model': 'llama-2-13b-chat', 'win_rate': 0.265},\n",
    "    {'model': 'llama-2-7b-chat', 'win_rate': 0.174},\n",
    "    {'model': 'mistral-7b-instruct', 'win_rate': 0.329},\n",
    "    {'model': 'mistral-medium', 'win_rate': 0.309},\n",
    "    {'model': 'mixtral-8x7b-instruct-v0.1', 'win_rate': 0.571},\n",
    "    {'model': 'palm-2', 'win_rate': 0.693},\n",
    "    {'model': 'qwen1.5-72b-chat', 'win_rate': 0.671},\n",
    "    {'model': 'yi-34b-chat', 'win_rate': 0.626},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>response_length</th>\n",
       "      <th>long_response</th>\n",
       "      <th>comparisons</th>\n",
       "      <th>often_compared</th>\n",
       "      <th>first_comparisons</th>\n",
       "      <th>first_percent</th>\n",
       "      <th>often_first</th>\n",
       "      <th>formatted</th>\n",
       "      <th>often_formatted</th>\n",
       "      <th>open_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>0.915</td>\n",
       "      <td>1300.464933</td>\n",
       "      <td>0</td>\n",
       "      <td>4306</td>\n",
       "      <td>1</td>\n",
       "      <td>2167</td>\n",
       "      <td>0.503251</td>\n",
       "      <td>1</td>\n",
       "      <td>2723</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>0.756</td>\n",
       "      <td>2295.297948</td>\n",
       "      <td>1</td>\n",
       "      <td>5360</td>\n",
       "      <td>1</td>\n",
       "      <td>2669</td>\n",
       "      <td>0.497948</td>\n",
       "      <td>0</td>\n",
       "      <td>4564</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palm-2</td>\n",
       "      <td>0.693</td>\n",
       "      <td>888.247034</td>\n",
       "      <td>0</td>\n",
       "      <td>1433</td>\n",
       "      <td>0</td>\n",
       "      <td>734</td>\n",
       "      <td>0.512212</td>\n",
       "      <td>1</td>\n",
       "      <td>686</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qwen1.5-72b-chat</td>\n",
       "      <td>0.671</td>\n",
       "      <td>1760.043243</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yi-34b-chat</td>\n",
       "      <td>0.626</td>\n",
       "      <td>2074.278520</td>\n",
       "      <td>1</td>\n",
       "      <td>973</td>\n",
       "      <td>0</td>\n",
       "      <td>465</td>\n",
       "      <td>0.477903</td>\n",
       "      <td>0</td>\n",
       "      <td>812</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
       "      <td>0.571</td>\n",
       "      <td>1622.423525</td>\n",
       "      <td>1</td>\n",
       "      <td>2406</td>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.487116</td>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>1224.380241</td>\n",
       "      <td>0</td>\n",
       "      <td>1741</td>\n",
       "      <td>0</td>\n",
       "      <td>908</td>\n",
       "      <td>0.521539</td>\n",
       "      <td>1</td>\n",
       "      <td>1377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deepseek-llm-67b-chat</td>\n",
       "      <td>0.546</td>\n",
       "      <td>1336.406551</td>\n",
       "      <td>0</td>\n",
       "      <td>519</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0.545279</td>\n",
       "      <td>1</td>\n",
       "      <td>369</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>0.494</td>\n",
       "      <td>1247.284203</td>\n",
       "      <td>0</td>\n",
       "      <td>3969</td>\n",
       "      <td>1</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1</td>\n",
       "      <td>3061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gemini-pro</td>\n",
       "      <td>0.474</td>\n",
       "      <td>1382.902778</td>\n",
       "      <td>0</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0.499008</td>\n",
       "      <td>0</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>claude-instant-1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>1304.210472</td>\n",
       "      <td>0</td>\n",
       "      <td>2922</td>\n",
       "      <td>1</td>\n",
       "      <td>1455</td>\n",
       "      <td>0.497947</td>\n",
       "      <td>0</td>\n",
       "      <td>2309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1407.265105</td>\n",
       "      <td>1</td>\n",
       "      <td>4866</td>\n",
       "      <td>1</td>\n",
       "      <td>2448</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>1</td>\n",
       "      <td>3043</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>0.329</td>\n",
       "      <td>1203.310565</td>\n",
       "      <td>0</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>534</td>\n",
       "      <td>0.486339</td>\n",
       "      <td>0</td>\n",
       "      <td>643</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1863.079785</td>\n",
       "      <td>1</td>\n",
       "      <td>2231</td>\n",
       "      <td>1</td>\n",
       "      <td>1145</td>\n",
       "      <td>0.513223</td>\n",
       "      <td>1</td>\n",
       "      <td>1807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>0.265</td>\n",
       "      <td>1706.378180</td>\n",
       "      <td>1</td>\n",
       "      <td>1769</td>\n",
       "      <td>1</td>\n",
       "      <td>875</td>\n",
       "      <td>0.494630</td>\n",
       "      <td>0</td>\n",
       "      <td>1553</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>llama-2-7b-chat</td>\n",
       "      <td>0.174</td>\n",
       "      <td>1780.380750</td>\n",
       "      <td>1</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>553</td>\n",
       "      <td>0.471039</td>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  win_rate  response_length  long_response  \\\n",
       "0                   gpt-4-0613     0.915      1300.464933              0   \n",
       "1           gpt-4-1106-preview     0.756      2295.297948              1   \n",
       "2                       palm-2     0.693       888.247034              0   \n",
       "3             qwen1.5-72b-chat     0.671      1760.043243              1   \n",
       "4                  yi-34b-chat     0.626      2074.278520              1   \n",
       "5   mixtral-8x7b-instruct-v0.1     0.571      1622.423525              1   \n",
       "6                   claude-2.0     0.550      1224.380241              0   \n",
       "7        deepseek-llm-67b-chat     0.546      1336.406551              0   \n",
       "8                   claude-2.1     0.494      1247.284203              0   \n",
       "9                   gemini-pro     0.474      1382.902778              0   \n",
       "10            claude-instant-1     0.455      1304.210472              0   \n",
       "11          gpt-3.5-turbo-0613     0.408      1407.265105              1   \n",
       "12         mistral-7b-instruct     0.329      1203.310565              0   \n",
       "13              mistral-medium     0.309      1863.079785              1   \n",
       "14            llama-2-13b-chat     0.265      1706.378180              1   \n",
       "15             llama-2-7b-chat     0.174      1780.380750              1   \n",
       "\n",
       "    comparisons  often_compared  first_comparisons  first_percent  \\\n",
       "0          4306               1               2167       0.503251   \n",
       "1          5360               1               2669       0.497948   \n",
       "2          1433               0                734       0.512212   \n",
       "3           370               0                190       0.513514   \n",
       "4           973               0                465       0.477903   \n",
       "5          2406               1               1172       0.487116   \n",
       "6          1741               0                908       0.521539   \n",
       "7           519               0                283       0.545279   \n",
       "8          3969               1               2058       0.518519   \n",
       "9          1008               0                503       0.499008   \n",
       "10         2922               1               1455       0.497947   \n",
       "11         4866               1               2448       0.503083   \n",
       "12         1098               0                534       0.486339   \n",
       "13         2231               1               1145       0.513223   \n",
       "14         1769               1                875       0.494630   \n",
       "15         1174               0                553       0.471039   \n",
       "\n",
       "    often_first  formatted  often_formatted  open_source  \n",
       "0             1       2723                1            0  \n",
       "1             0       4564                1            0  \n",
       "2             1        686                0            0  \n",
       "3             1        274                0            1  \n",
       "4             0        812                0            1  \n",
       "5             0       1930                1            1  \n",
       "6             1       1377                0            0  \n",
       "7             1        369                0            1  \n",
       "8             1       3061                1            0  \n",
       "9             0        702                0            0  \n",
       "10            0       2309                1            0  \n",
       "11            1       3043                1            0  \n",
       "12            0        643                0            1  \n",
       "13            1       1807                1            0  \n",
       "14            0       1553                1            1  \n",
       "15            0        898                0            1  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = helm_df[['model', 'win_rate']].merge(groups_df, on='model')\n",
    "\n",
    "# recalculate top/bottom 50%\n",
    "_df['long_response'] = (_df.response_length > _df.response_length.median()).astype(int)\n",
    "_df['often_compared'] = (_df.comparisons > _df.comparisons.median()).astype(int)\n",
    "_df['often_first'] = (_df.first_percent > _df.first_percent.median()).astype(int)\n",
    "_df['often_formatted'] = (_df.formatted > _df.formatted.median()).astype(int)\n",
    "helm_combined = _df\n",
    "\n",
    "helm_combined.sort_values('win_rate', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
