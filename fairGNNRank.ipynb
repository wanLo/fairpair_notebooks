{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from itertools import product\n",
    "import multiprocessing\n",
    "\n",
    "from fairpair import *\n",
    "\n",
    "import sys\n",
    "sys.path.append('../GNNRank/')\n",
    "from src.param_parser import ArgsNamespace # just import the class, not the parser\n",
    "from src.Trainer_fair import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could install torchsort from: https://github.com/teddykoker/torchsort/releases/download/v0.1.9/torchsort-0.1.9+pt113cu117-cp311-cp311-linux_x86_64.whl\n",
    "\n",
    "â€¦or we just keep the \"raw\" scores instead of converting them to ranks to keep them differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f1e2638c390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = ArgsNamespace(AllTrain=True, ERO_style='uniform', F=70, Fiedler_layer_num=5, K=20, N=350, SavePred=False, all_methods=['DIGRAC', 'ib'],\n",
    "                     alpha=1.0, baseline='syncRank', cuda=True, data_path='/home/georg/fairpair/GNNRank/data/',\n",
    "                     dataset=f'fairGNNRank_test', be_silent=True,\n",
    "                     debug=False, device=torch.device(type='cpu'), dropout=0.5, early_stopping=500, epochs=1000, eta=0.1, fill_val=0.5, hidden=8, hop=2,\n",
    "                     load_only=True, log_root='/home/georg/fairpair/GNNRank/logs/', lr=0.1, no_cuda=False, num_trials=1, optimizer='Adam', p=0.05,\n",
    "                     pretrain_epochs=50, pretrain_with='dist', regenerate_data=True, season=1990, seed=31, seeds=[10], sigma=1.0, tau=0.5, test_ratio=1,\n",
    "                     train_ratio=1, train_with='proximal_baseline', trainable_alpha=False, upset_margin=0.01, upset_margin_coeff=0, upset_ratio_coeff=1.0, weight_decay=0.0005,\n",
    "                     exposure_coeff=0.9)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = FairPairGraph()\n",
    "G.generate_groups(40, 20) # same size groups\n",
    "G.assign_skills(loc=0, scale=0.86142674, seed=42) # general skill distribution\n",
    "G.assign_bias(nodes=G.minority_nodes, loc=-1.43574282, scale=0.43071336, seed=42) # add bias to unprivileged group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = RandomSampling(G, warn=False)\n",
    "sampler.apply(iter=500, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.array([group for node, group in G.nodes(data='minority')])\n",
    "adj = nx.linalg.graphmatrix.adjacency_matrix(G, weight='weight') # returns a sparse matrix\n",
    "\n",
    "trainer = Trainer(args, random_seed=10, save_name_base='test', adj=adj, groups=groups) # initialize with the given adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad7abf96bb14edc8b3262bc770d78e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path_best, save_path_latest = trainer.train(model_name='ib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, pred_label = trainer.predict_nn(model_name='ib', model_path=save_path_best, A=None, GNN_variant='proximal_baseline')\n",
    "ranking = {key: 1-score[0] for key, score in enumerate(score.cpu().detach().numpy())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall error 0.4107289246411511\n",
      "Majority error 0.4510969642998299\n",
      "Minority error 0.4792292247362133\n",
      "Majority exposure 0.34073936545202393\n",
      "Minority exposure 0.21381226908065512\n"
     ]
    }
   ],
   "source": [
    "ranking_as_ranks = scores_to_rank(ranking, invert=False)\n",
    "base_scores = [skill for node, skill in G.nodes(data='skill')]\n",
    "all_nodes = list(range(40))\n",
    "majority_nodes = list(range(20))\n",
    "minority_nodes = list(range(20,40))\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=all_nodes, complementary_nodes=[])\n",
    "print('Overall error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=majority_nodes, complementary_nodes=minority_nodes)\n",
    "print('Majority error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=minority_nodes, complementary_nodes=majority_nodes)\n",
    "print('Minority error', tau)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=majority_nodes)\n",
    "print('Majority exposure', exp)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=minority_nodes)\n",
    "print('Minority exposure', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 41])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -0.9098,  -0.3698,  -1.0860,   0.2894,   1.4565,  -0.5377,   0.4804,\n",
       "         -0.9171,   0.0276,  -0.3004,  -1.3027,   0.2954,   0.6090,  -0.2328,\n",
       "         -0.3737,  -0.7023,   0.0684,   0.0588,  -1.0150,  -0.5431,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "          0.0000,   0.0000,   0.0000,   0.0000,   0.0000, -10.0000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.features[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall error 0.38624295229956584\n",
      "Majority error 0.41828713175933113\n",
      "Minority error 0.45099082667388324\n",
      "Majority exposure 0.34213817706944416\n",
      "Minority exposure 0.2124134574632348\n"
     ]
    }
   ],
   "source": [
    "ranker = RankRecovery(G)\n",
    "scores, nodes = ranker.apply()\n",
    "ranking_as_ranks = scores_to_rank(scores, invert=False)\n",
    "base_scores = [skill for node, skill in G.nodes(data='skill')]\n",
    "all_nodes = list(range(40))\n",
    "majority_nodes = list(range(20))\n",
    "minority_nodes = list(range(20,40))\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=all_nodes, complementary_nodes=[])\n",
    "print('Overall error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=majority_nodes, complementary_nodes=minority_nodes)\n",
    "print('Majority error', tau)\n",
    "tau = weighted_tau_nodes(base_scores, ranking_as_ranks, subgraph_nodes=minority_nodes, complementary_nodes=majority_nodes)\n",
    "print('Minority error', tau)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=majority_nodes)\n",
    "print('Majority exposure', exp)\n",
    "exp = exposure_nodes(ranking_as_ranks, subgraph_nodes=minority_nodes)\n",
    "print('Minority exposure', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNNRank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
